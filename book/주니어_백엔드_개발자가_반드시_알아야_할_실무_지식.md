### ToC

- [2장. 느려진 서비스, 어디부터 봐야 할까](#2장-느려진-서비스-어디부터-봐야-할까)
  - [응답 시간(Response Time)](#응답-시간response-time)
  - [처리량(Throughput)](#처리량throughput)
  - [병목 지점(Bottleneck) 찾기](#병목-지점bottleneck-찾기)
  - [DB 커넥션 풀](#db-커넥션-풀)
    - [커넥션 풀 크기](#커넥션-풀-크기)
    - [커넥션 대기 시간](#커넥션-대기-시간)
    - [최대 유휴시간, 유효성 검사, 최대 유지 시간](#최대-유휴시간-유효성-검사-최대-유지-시간)
  - [서버 캐시](#서버-캐시)
    - [적중률과 삭제 규칙](#적중률과-삭제-규칙)
    - [로컬(Local) 캐시와 리모트(Remote) 캐시](#로컬local-캐시와-리모트remote-캐시)
    - [캐시 사전 적재](#캐시-사전-적재)
    - [캐시 무효화](#캐시-무효화)
  - [가비지 컬렉터와 메모리 사용](#가비지-컬렉터와-메모리-사용)
  - [응답 데이터 압축](#응답-데이터-압축)
  - [정적 자원과 브라우저 캐시](#정적-자원과-브라우저-캐시)
  - [정적 자원과 CDN](#정적-자원과-cdn)
  - [대기 처리](#대기-처리)
- [3장. 성능을 좌우하는 DB 설계와 쿼리](#3장-성능을-좌우하는-db-설계와-쿼리)
  - [성능에 핵심인 DB](#성능에-핵심인-db)
  - [조회 트래픽을 고려한 인덱스 설계](#조회-트래픽을-고려한-인덱스-설계)
    - [단일 인덱스와 복합 인덱스](#단일-인덱스와-복합-인덱스)
    - [선택도를 고려한 인덱스 컬럼 선택](#선택도를-고려한-인덱스-컬럼-선택)
    - [커버링 인덱스 활용하기](#커버링-인덱스-활용하기)
    - [인덱스는 필요한 만큼만 만들기](#인덱스는-필요한-만큼만-만들기)
  - [몇 가지 조회 성능 개선 방법](#몇-가지-조회-성능-개선-방법)
    - [미리 집계하기](#미리-집계하기)
  - [알아두면 좋을 몇 가지 주의 사항](#알아두면-좋을-몇-가지-주의-사항)
    - [쿼리 타임아웃](#쿼리-타임아웃)
    - [상태 변경 기능은 복제 DB에서 조회하지 않기](#상태-변경-기능은-복제-db에서-조회하지-않기)
    - [배치 쿼리 실행 시간 증가](#배치-쿼리-실행-시간-증가)
    - [타입이 다른 컬럼 조인 주의](#타입이-다른-컬럼-조인-주의)
    - [테이블 변경은 신중하게](#테이블-변경은-신중하게)
    - [DB 최대 연결 개수](#db-최대-연결-개수)
  - [실패와 트랜잭션 고려하기](#실패와-트랜잭션-고려하기)
- [4장. 외부 연동이 문제일 때 살펴봐야 할 것들](#4장-외부-연동이-문제일-때-살펴봐야-할-것들)
  - [타임아웃](#타임아웃)
    - [2가지 타임아웃: 연결 타임아웃, 읽기 타입아웃](#2가지-타임아웃-연결-타임아웃-읽기-타입아웃)
    - [타임아웃간의 차이 정리](#타임아웃간의-차이-정리)
  - [재시도](#재시도)
    - [재시도 가능 조건](#재시도-가능-조건)
    - [재시도 횟수와 간격](#재시도-횟수와-간격)
    - [재시도 폭풍(Retry Storm) 안티패턴](#재시도-폭풍retry-storm-안티패턴)
  - [동시 요청 제한](#동시-요청-제한)
  - [서킷 브레이커](#서킷-브레이커)
  - [외부 연동과 DB 연동](#외부-연동과-db-연동)
    - [외부 연동과 트랜잭션 처리](#외부-연동과-트랜잭션-처리)
    - [외부 연동은 성공했는데 DB 연동에 실패해서 트랜잭션을 롤백](#외부-연동은-성공했는데-db-연동에-실패해서-트랜잭션을-롤백)
    - [외부 연동이 느려질 때 DB 커넥션 풀 문제](#외부-연동이-느려질-때-db-커넥션-풀-문제)
  - [HTTP 커넥션 풀](#http-커넥션-풀)
- [5장. 비동기 연동, 언제 어떻게 써야 할까?](#5장-비동기-연동-언제-어떻게-써야-할까)
  - [동기 연동과 비동기 연동](#동기-연동과-비동기-연동)
  - [별도 스레드로 실행하기](#별도-스레드로-실행하기)
  - [메시징](#메시징)
    - [메시지 생성 측 고려 사항](#메시지-생성-측-고려-사항)
  - [트랜잭션 아웃박스 패턴](#트랜잭션-아웃박스-패턴)
- [6장. 동시성, 데이터가 꼬이기 전에 잡아야 한다.](#6장-동시성-데이터가-꼬이기-전에-잡아야-한다)
  - [프로세스 수준에서의 동시 접근 제어](#프로세스-수준에서의-동시-접근-제어)
    - [잠금(Lock)을 이용한 접근 제어](#잠금lock을-이용한-접근-제어)
    - [동시 접근을 위한 구성 요소](#동시-접근을-위한-구성-요소)
    - [세마포어(Semaphore)](#세마포어semaphore)
    - [읽기 쓰기 잠금(Reader-Writer Lock)](#읽기-쓰기-잠금reader-writer-lock)
    - [원자적 타입 (Atomic Type)](#원자적-타입-atomic-type)
    - [동시성 지원 컬렉션](#동시성-지원-컬렉션)
  - [DB와 동시성](#db와-동시성)
    - [선점(비관적) 잠금(Pessimistic Locking)](#선점비관적-잠금pessimistic-locking)
    - [비선점(낙관적) 잠금(Optimistic Locking)](#비선점낙관적-잠금optimistic-locking)
    - [외부 연동과 잠금](#외부-연동과-잠금)
    - [증분 쿼리](#증분-쿼리)
  - [잠금 사용 시 주의 사항](#잠금-사용-시-주의-사항)
    - [잠금 해제하기](#잠금-해제하기)
    - [대기 시간 지정하기](#대기-시간-지정하기)
    - [교착 상태(deadlock) 피하기](#교착-상태deadlock-피하기)
  - [단일 스레드로 처리하기](#단일-스레드로-처리하기)
- [7장. I/O 병목, 어떻게 해결하지](#7장-io-병목-어떻게-해결하지)
  - [가상 스레드로 자원 효율 높이기](#가상-스레드로-자원-효율-높이기)
    - [네트워크 IO와 가상 스레드](#네트워크-io와-가상-스레드)
    - [가상 스레드와 성능](#가상-스레드와-성능)
    - [Spring에서 Async 비교](#spring에서-async-비교)
  - [논블로킹 IO로 성능 더 높이기](#논블로킹-io로-성능-더-높이기)
    - [논블로킹 IO 동작 개요](#논블로킹-io-동작-개요)
    - [리액터 패턴](#리액터-패턴)
    - [논블로킹/비동기 IO와 성능](#논블로킹비동기-io와-성능)
  - [언제 어떤 방법을 택할까](#언제-어떤-방법을-택할까)
- [8장. 실무에서 꼭 필요한 보안 지식](#8장-실무에서-꼭-필요한-보안-지식)
  - [인증과 인가](#인증과-인가)
    - [인가와 접근 제어 모델](#인가와-접근-제어-모델)
    - [Salt로 보안 강화하기](#salt로-보안-강화하기)
    - [양방향 암호화](#양방향-암호화)
- [9장. 최소한 알고 있어야 할 서버 지식](#9장-최소한-알고-있어야-할-서버-지식)
  - [파일 디스크립터 제한](#파일-디스크립터-제한)
  - [네트워크 정보 확인](#네트워크-정보-확인)
    - [nc 명령어로 연결 확인하기](#nc-명령어로-연결-확인하기)
    - [netstat 명령어로 포트 확인하기](#netstat-명령어로-포트-확인하기)

# 2장. 느려진 서비스, 어디부터 봐야 할까

다양한 지표가 성능과 관련이 있다. 네트워크 속도, 디스크 속도, CPU 속도, 메모리 크기, GC 속도 등 다양한 지표가 성능과 관련이 있다.
이런 다양한 지표 중에서 서버 성능과 관련 있는 중요한 지표를 2가지 꼽자면 응답 시간(Response Time)과 처리량(Throughput)이다.

## 응답 시간(Response Time)

```mermaid
sequenceDiagram
    participant App as 앱
    participant APIServer as API 서버
    participant DBMS

    %% 1. 앱이 API 서버에 요청을 보냄
    App->>APIServer: 요청(Request)
    %% 2. API 서버가 DBMS에 데이터 질의
    APIServer->>DBMS: 데이터 질의(Query)
    %% 3. DBMS가 API 서버에 질의 결과 반환
    DBMS-->>APIServer: 질의 결과(Result)
    %% 4. API 서버가 앱에 응답 반환
    APIServer-->>App: 응답(Response)
```

**그림 1.** 앱, API 서버, DBMS 간의 시퀀스 다이어그램

1. API 요청: 서버에 연결 + 서버로 데이터 전송
2. SQL 실행, 응답 생성 등: 서버 실행
3. API 응답: 클라이언트로 데이터 전송

응답 시간은 다음과 같이 2가지로 나누어 측정하기도 한다.

- TTFB(Time to First Byte): 첫 번째 바이트가 도착하기까지의 시간
- TTLB(Time to Last Byte): 마지막 바이트가 도착하기까지의 시간

파일 다운로드처럼 전송할 데이터가 크거나 네트워크 속도가 느리면 TTFB와 TTLB의 차이가 커질 수 있다.

서버 개발자는 주로 서버의 처리 시간을 확인한다. 서버 처리 시간은 다음과 같은 요소를 포함한다.

- 로직 수행(if, for 등)
- DB 연동(SQL 실행)
- 외부 API 연동
- 응답 데이터 생성(전송)

이 중에서도 DB 연동과 외부 API 연동이 큰 비중을 차지한다. 실제 한 요청의 처리 시간을 측정한 결과다.

- 전체 처리 시간: 348ms
- API 연동 1(External API) 186ms(53%)
- API 연동 2(Internal API) 44ms(13%)
- DB 연동(SQL 실행 6회): 101ms(29%)
- 응답 데이터 생성: 17ms(5%)

이처럼 API 연동과 DB 연동이 전체 처리 시간의 대부분을 차지하는 경우가 많다. 이러한 이유로 응답 시간을 줄일 때 DB 연동과 API 연동 시간에 집중한다.

## 처리량(Throughput)

처리량은 단위 시간당 처리할 수 있는 요청의 수를 의미한다. 흔히 TPS(Transaction Per Second: 초당 처리한 트랜잭션 수), RPS(Request Per Second) 등으로 표현한다.

최대 TPS는 시스템이 처리할 수 있는 최대 요청 수를 의미한다. 동시에 들어오는 요청 수가 최대 TPS를 초과하면 서버는 초과한 요청을 나중에 처리한다. 예를 들어, 최대 TPS가 5인 서버에 동시에 7개의 요청이 들어오면 5개는 즉시 처리하고 나머지 2개는 대기한다. 나머지 2개는 5개의 요청이 끝난 후에야 처리된다. 사용자 입장에서는 나중에 처리된 2개의 요청은 **실제 처리된 시간과 더불어서 대기 시간도 포함된다.**

응답 시간의 증가는 사용자 이탈로 이어질 수 있다. 이를 방지하려면 다음 2가지 방법을 고려해야 한다.

1. 서버가 동시에 처리할 수 있는 요청 수를 늘려 대기 시간을 줄인다.
2. 처리 시간 자체를 줄여 대기 시간을 줄인다.

> [!TIP]
> 성능을 개선하려면 먼저 현재 서버의 TPS와 응답 시간을 알아야 한다.
> 막연히 성능이 느리다 말하면서 이것저것 시도하면 안 된다.
> 트래픽이 많은 시간대의 TPS와 응답 시간이 얼마인지 측정하고,
> 이 결과를 바탕으로 목표 TPS와 응답 시간을 설정하고 효과적인 성능 개선안을 도출해야한다.
>
> **TPS를 확인하는 가장 간단한 방법은 모니터링 시스템을 활용하는 것이다.**

## 병목 지점(Bottleneck) 찾기

트래픽이 증가하면서 성능 문제가 발생하는 주된 이유는 시스템이 수용할 수 있는 최대 TPS를 초과하는 트래픽이 유입되기 때문이다. 시스템이 제공할 수 있는 최대 TPS를 높이지 않으면 증가하는 트래픽을 적절히 처리할 수 없다.

TPS를 높이려면 먼저 성능 문제가 발생하는 지점을 찾아야 한다. 문제 지점을 찾는 간단한 방법은 처리 시간이 오래 걸리는 작업을 식별하는 것이다.

TPS를 높이기 위해 무턱대고 서버를 추가해서는 안 된다.

> [!TIP]
>
> **병목 지점(Bottleneck)을 확인하는 가장 간단한 방법은 APM 시스템을 활용하는 것이다.**

## DB 커넥션 풀

DB를 사용하려면 다음과 같이 3단계의 과정이 필요하다.

1. DB에 연결한다.
2. SQL을 실행한다.
3. 사용이 끝나면 DB 연결을 종료한다.

서버와 DB는 네트워크 통신을 통해 연결된다. 이때 네트워크 연결을 생성하고 종료하는 데 걸리는 시간은 0.5초에서 1초 이상 소요되기도 한다. 이 시간이 길게 느껴지지 않을 수도 있지만 실제로는 매우 긴 시간이다. 예를 들어, 10ms에 불과한 짧은 쿼리를 실행하기 위해 연결과 종료에 50ms(0.05초)가 소요된다면 전체 처리 시간은 60ms(0.06초)가 된다. 단순히 계산해도 전체 처리 시간의 80% 이상이 DB 연결 및 종료에 쓰이게 된다.

매 요청마다 DB를 연결하고 종료하면 트래픽이 증가하면 이러한 현상은 더 두드러진다. 매 요청마다 DB를 연결하고 종료하면 트래픽이 증가할 때 급격하게 처리량이 떨어지기도 한다. 이런 문제를 피하기 위해 DB 커넥션 풀을 사용한다. DB 커넥션 풀은 DB에 연결된 커넥션을 미리 생성해서 보관한다. 애플리케이션은 DB 작업이 필요할 때 풀에서 커넥션을 가져와 사용하고, 작업이 끝나면 다시 풀에 반환한다.

커넥션 풀 설정중 중요한 설정은 다음과 같다.

- 커넥션 풀 크기(또는 최소, 최대 크기)
- 풀에 커넥션이 없을 때 커넥션을 구할 때까지 대기할 시간
- 커넥션의 유지 시간(최대 유휴 시간, 최대 유지 시간)

### 커넥션 풀 크기

커넥션 풀 크기는 커넥션 풀에 보관할 수 있는 커넥션의 개수를 의미한다. 서버는 주로 DB와 통신을 하기 때문에, DB 커넥션 풀 크기를 잘못 설정하면 성능에 큰 영향을 미친다. 다음과 같은 상황을 가정해보자.

- 커넥션 풀 크기는 5다.
- 한 요청에서 쿼리를 실행하는데 1초 걸린다.
- 계산을 쉽게 하기 위해 데이터 전송 시간은 무시한다.

서버에 6개 요청이 동시에 들어왔을 때 이 중 5개 요청은 풀에서 커넥션을 가져올 수 있다. 반면 1개 요청은 다른 요청이 커넥션을 반환할 때까지 대기해야 한다.

커넥션 풀의 구현 방식에 따라 다르지만 일반적인 커넥션 풀은 최소 크기와 최대 크기를 설정할 수 있다. 최소 크기는 커넥션 풀에 항상 유지할 커넥션의 개수를 의미한다. 커넥션 풀의 크기를 5로 설정하고 최소 크기를 2로 설정하면 커넥션 풀은 항상 2개의 커넥션을 유지한다. 나머지 3개는 필요할 때마다 생성된다. 이때 커넥션 풀의 크기를 5로 설정하면 최대 5개의 커넥션을 유지할 수 있다.

> [!Tip]
> 트래픽이 순간적으로 급증하는 패턴을 보인다면 커넥션 풀의 최소 크기를 최대 크기에 맞추는 것이 좋다.
> 트래픽이 점진적으로 증가할 때는 DB 연결 시간이 성능에 큰 영향을 주지 않지만 트래픽이 급증할 때는
> DB 연결도 성능 저하의 주요 원인이 될 수 있기 때문이다.

### 커넥션 대기 시간

대기 시간이란 풀에 사용할 수 있는 커넥션이 없을 때 커넥션을 얻기 위해 기다릴 수 있는 최대 시간을 의미한다. 지정된 대기 시간 안에 커넥션을 얻지 못하면 DB 연결 실패 에러가 발생한다.

> [!Tip]
> 따라서 응답 시간이 중요한 서비스는 커넥션 대기 시간을 가능한 한 짧게 설정해야 한다.
> 트래픽의 양이나 서비스의 특성에 따라 차이는 있지만 보통의 경우라면 0.5초에서 3초 이내로 지정하자.
> **모니터링 시스템(APM 등)을 통해 커넥션 대기 시간, 실패율, 응답 시간 등의 지표를 수집한다.**  
> **실시간성이 중요한 서비스라면 짧게, 배치성이나 대기 허용 서비스라면 길게 설정한다.**  
> **금융 거래처럼 반드시 처리가 되어야 하는 경우라면 대기 시간을 더 길게 설정한다.**
>
> **실제 적용 방법**
>
> 1. 초기에는 0.5초~3초로 설정한다. (예: 500ms ~ 3000ms)
> 2. 모니터링
>
>    - 커넥션 풀에서 대기 시간이 자주 발생하는지
>    - 대기 시간 초과로 실패하는 요청이 얼마나 되는지 모니터링
>
> 3. 조정
>
>    - 대기 시간 초과가 많으면 풀 크기를 늘리거나, 대기 시간을 늘리거나, 쿼리 성능을 개선하는 튜닝이 필요하다.

대기 시간을 짧게 설정하면 커넥션 풀이 모두 사용중일 때 빠르게 '일시적 오류'와 같은 에러 응답을 사용자에게 보여줄 수 있다. 에러를 응답하는게 부정적으로 보일 수도 있다.
하지만 대기 시간 때문에 긴 시간 동안 무응답 상태가 되는 것보다는 나을 수 있다. 커넥션을 얻지 못했을 때 에러를 응답해야 서버의 부하가 증가하는 것도 방지할 수 있다.

### 최대 유휴시간, 유효성 검사, 최대 유지 시간

근무 시간대에는 지속적으로 서버에 요청이 들어오지만 새벽 시간대에는 요청이 거의 없을 것이다. 요청이 없는 시간대에는 풀에 있는 커넥션도 사용되지 않는다.
이때 주의할 점이 있다. 커넥션이 사용되지 않는 시간이 길어지면 연결이 끊길 수 있다.

DB와의 연결이 끊긴 커넥션을 사용하면 에러가 발생한다. 이러한 연결 끊김으로 인해 발생하는 에러를 방지하기 위해 커넥션 풀은 다음 2가지 기능을 제공한다.

- 최대 유휴시간(Maximum Idle Time) 지정
- 유효성 검사(Validation) 지원

최대 유휴 시간은 사용되지 않는 커넥션을 풀에 유지할 수 있는 최대 시간을 의미한다.
최대 유휴 시간을 30분으로 설정하면 30분 이상 사용되지 않은 커넥션은 종료되어 풀에서 제거된다.
이 시간을 DB에 설정된 비활성화 유지 시간보다 짧게 설정하면, DB가 연결을 끊기 전에 풀에서 커넥션을 제거할 수 있다.

유효성 검사는 커넥션이 정상적으로 사용할 수 있는 상태인지 여부를 확인하는 절차이다.
이 과정을 통해 커넥션 풀에 존재하는 커넥션 중 연결이 유요하지 않은 커넥션을 식별하고 풀에서 제거할 수 있다.
일부 커넥션 풀은 유효성 검사를 위해 실제 쿼리를 실행하기도 한다. 이때는 `SELECT 1`, `SELECT 1 FROM DUAL`과 같은 간단한 쿼리를 사용한다.

커넥션 풀이 제공하는 또 다른 설정은 최대 유지 시간이다. 이 갑싱 4시간으로 설정되면 커넥션은 생성된 후 최대 4시간 동안만 유지된다. 4시간이 지나면 커넥션은 유효하더라도 커넥션을 닫고 풀에서 제거된다.

> [!TIP]
> 최대 유휴 시간과 최대 유지 시간을 무한대로 설정하지 않는 것이 좋다.
> 커넥션 풀의 기본값을 확인한 뒤 이 두 설정의 기본값이 무제한으로 되어 있다면 DB 설정을 참고하여 알맞게 적절한 값으로 지정해야 한다.

## 서버 캐시

DB 서버를 수평 확장하더라도 처리량을 늘릴 수 있지만 실행 시간이 획기적으로 줄어들지는 않는다.
DB 서버를 확장하지 않고도 응답 시간과 처리량을 개선하고 싶다면 캐시(Cache) 사용을 고려할 수 있다.

```mermaid
---
title: 캐시의 동작 방식
---

stateDiagram-v2
    getFromCache: 캐시에서 해당하는 값 조회
    [*] --> getFromCache

    state isEmpty <<choice>>
    getFromCache --> isEmpty

    useCache: 값 사용
    isEmpty --> useCache: [값 존재]

    getFromDB: DB에서 값 조회
    isEmpty --> getFromDB: [값 없음]
    saveCache: (키, 값)을 캐시에 저장
    getFromDB --> saveCache
    saveCache --> useCache
    useCache --> [*]
```

> [!NOTE]
> 적절한 캐시 키를 선택해야한다. 예를 들어
> 게시글 상세 정보는 "artices:번호" 형태의 캐시 키를 사용하고 최신 인기 글은 "articles:hot10" 형태의 캐시 키를 사용하는 식이다.
> 또한 캐시를 사용할 때는 캐시 키가 겹치지 않도록 주의해야 한다.

### 적중률과 삭제 규칙

캐시에 보관할 수 있는 데이터에 제한이 있으므로, 캐시가 가득 차 있는 상태에서 데이터를 캐시에 저장하면 기존에 있는 데이터 중 하나를 제거해야 한다.
삭제할 대상을 선택할 때 주로 사용하는 규칙은 다음과 같다.

- LRU(Least Recently Used): 가장 오래전에 사용된 데이터를 삭제한다.
- LFU(Least Frequently Used): 가장 적게 사용된 데이터를 삭제한다.
- FIFO(First In First Out): 먼저 추가된 데이터를 삭제한다.

오래된 데이터는 캐시에 있어도 사용되지 않을 가능성이 크다.
따라서 캐시가 가득 차 있지 않더라도 오래된 데이터는 미리 삭제하는 것이 좋다.
이를 위해 캐시에는 유효 시간(TTL, i.g.만료 시간)을 설정하는 방식도 함께 사용한다.

### 로컬(Local) 캐시와 리모트(Remote) 캐시

서버가 사용하는 캐시는 크게 두 종류가 있다. 첫 번째는 로컬(Local) 캐시다.
로컬 캐시는 서버 프로세스와 동일한 메모리를 캐시 저장소로 사용한다.
두 번째는 리모트(Remote) 캐시다. 리모트 캐시는 별도 프로세스를 캐시 저장소로 사용한다.

로컬 캐시 구현 기술로는 Caffeine(Java), go-cache(Go), node-cache(Node.js)등이 있다.
로컬 캐시의 장점은 속도에 있다.
또한 별도의 외부 연동이 필요하지 않아 구조를 단순하게 유지할 수 있다.

| 구분          | 로컬(Local) 캐시                                                                                                                                           | 리모트(Remote) 캐시                                                                                                                                                |
| :------------ | :--------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **장점**      | - 매우 빠른 응답 속도 (메모리 접근)<br>• 네트워크 지연 없음<br> - 구현이 단순하고 외부 의존성 없음<br> - 외부 시스템 연동 불필요                           | - 여러 서버 간 캐시 데이터 공유 가능<br> -서버 확장에도 일관된 캐시 유지<br> - 서버 재시작해도 캐시 유지<br> - 대용량 데이터 캐싱 가능<br> - 중앙 집중식 캐시 관리 |
| **단점**      | - 서버마다 별도 캐시 관리 필요<br> - 서버 재시작 시 캐시 소실<br> - 서버 간 캐시 데이터 불일치 발생<br> - 메모리 제약으로 캐시 크기 제한<br> - 확장성 제한 | - 네트워크 지연 발생<br> - 외부 시스템 의존성 증가<br> - 구현 및 운영 복잡도 증가<br> - 네트워크 비용 발생<br> - 외부 서비스 장애 시 영향                          |
| **적합 사례** | - 변경이 적은 정적 데이터<br> - 서버별 독립적 데이터<br> - 초고속 응답이 필요한 경우<br> - 단일 서버 환경                                                  | - 다중 서버 환경<br> - 일관된 캐시 데이터 필요 시<br> - 대규모 캐시 데이터 필요 시<br> - 서버 재시작에도 데이터 유지 필요 시                                       |
| **구현 기술** | - Caffeine (Java)<br> - go-cache (Go)<br> - node-cache (Node.js)                                                                                           | - Valkey<br> - Memcached<br> - Hazelcast                                                                                                                           |

로컬 캐시와 리모트 캐시는 각각 장단점이 뚜렷하기 때문에 상황이나 용도에 맞게 선택해야 한다.
어떤 방식을 무조건 선택해야 한다는 절대적인 기준은 없으며 데이터 규모, 변경 빈도, 응답 시간, 처리량 등을 판단 기준으로 결정해야 한다.

캐시에 보관할 데이터 규모가 작고 변경 빈도가 매우 낮다면 로컬 캐시로 충분하다.
예를 들어 홈 화면에 표시할 최신 공지글 목록을 생각해보자. 보통 이 목록은 많아야 10개 미만이다.
또한 몇 시간에서 며칠 동안 동일할 때가 많다.
이처럼 자주 바뀌지 않고 크기가 작은 데이터는 로컬 캐시를 사용하기에 적당하다.

반면에 데이터 규모가 크다면 리모트 캐시를 사용해야 한다.
대형 이커머스 사이트의 개별 제품 정보가 그 예다.
로컬 캐시로는 메모리 용량 등의 한계로 대응이 어렵다.
일부 데이터를 로컬 캐시에 저장하더라도 데이터가 수시로 변경되면 캐시 효율도 떨어진다.

### 캐시 사전 적재

트래픽이 순간적으로 급증하는 패턴을 보인다면 캐시에 데이터를 미리 저장하는 것도 고려할 필요가 있다.
다음은 캐시에 미리 데이터를 저장하면 큰 효과를 볼 수 있는 가상의 사례다.

- G 앱 사용자는 300만명
- 매달 정해진 날에 이달의 요금 정보를 보여준다.
- 해당 일자가 되면 전체 회원을 대상으로 요금 안내 푸시 알림을 발송한다.
- 푸시를 받은 사용자 중 일부는 이달의 요금 정보를 조회한다.

대응 방법은 캐시에 데이터를 미리 넣어두는 것이다.
각 사용자의 요금 정보를 캐시에 저장해두면 푸시를 받은 사용자가 한꺼번에 몰려올 때도 캐시 적중률을 99%에 가깝게 유지할 수 있다.
이를 통해 순간적으로 트래픽이 몰렸을 때도 응답 시간을 안정적으로 유지할 수 있으며, DB에 부하가 집중되는 현상도 효과적으로 방지할 수 있다.

### 캐시 무효화

캐시에 보고나된 데이터의 원본이 바뀌면, 그에 맞춰 캐시에 보관된 데이터도 함께 변경하거나 삭제해야 한다.
원본이 변경됐는데 캐시에 저장된 데이터가 갱신되지 않으면 사용자는 오래된 잘못된 정보를 확인하게 되는 문제가 발생할 수 있다.

캐시에 저장된 데이터의 특성에 따라 캐시를 무효화하는 시점을 달리 설정해야 한다.
가격 정보, 게시글 내용처럼 민감한 데이터는 변경되는 즉시 캐시를 무효화해야 한다.
게시글 내용을 수정했는데도 캐시가 그대로 유지되면 사용자는 수정 전 게시글 내용을 보게 되어 혼란을 겪을 수 있다.
작성자는 수정이 제대로 반영되지 않았다고 생각해 오류 신고를 하거나 서비스에 대한 신뢰도를 낮게 평가할 수 있다.

변경에 민감한 데이터는 로컬 캐시가 아닌 리모트 캐시에 보관해야 한다.
A 서버에 연결한 사용자는 변경된 가격 정보를 보지만 B 서버에 연결한 사용자는 B 서버의 로컬 캐시에 보관된 변경전 가격 정보를 보게 되는 문제가 발생할 수 있어 서비스 신뢰성에 큰 영향을 줄 수 있다.

변경에 민감하지 않고 데이터 크기가 작다면 캐시의 유효 시간을 설정하여 주기적으로 갱신하는 방식을 사용해도 된다.
예를 들어, 최근 인기 글 목록을 캐시에 저장한 경우, 최근 인기 글 목록이 바뀌고 몇 분 뒤에 캐시 데이터가 변경되더라도 서비스에 심각한 문제는 일어나지 않는다.
인기 글 목록을 저장하는 캐시의 유효 시간을 10분으로 지정하면 10분 주기로 최신 인기 게시글 목록을 갱신하는 효과를 얻을 수 있다. 갱신 시간을 줄이고 싶으면 유효 시간을 10분에서 5분으로 줄이기만 하면 된다.

## 가비지 컬렉터와 메모리 사용

가비지 컬렉터(Garbage Collector, GC)를 사용하는 언어는 사용이 끝난 객체를 힙 메모리에서 바로 삭제하지 않고 정해진 규칙에 따라 사용하지 않는 메모리를 정리한다.

메모리를 많이 사용하고 생성된 객체가 많을수록 사용하지 않는 객체를 찾는 데 시간이 오래 걸린다.
GC 알고리즘과 메모리 사용 패턴에 따라 차이가 있지만 사용하는 메모리양과 객체 수가 많을 수록 GC가 실행되는 시간이 길어진다.

반대로 메모리 사용을 줄이면 GC가 실행되는 시간도 줄어든다.
물론 실제 애플리케이션이 4GiB에 가까운 메모리가 있어야 하는데도 2GiB로 설정하면 OOM(Out Of Memory) 에러가 발생할 수 있으므로 실제 메모리 사용 패턴에 맞게 최대 힙 크기를 조정해야 한다.

한 번에 대량으로 객체르 생성하는 것도 주의해야 한다.
게시글 하나가 0.5KiB라고 가정했을 때 10만 개의 게시글은 대략 50MiB의 메모리를 사용한다.
만약 동시에 100명 사용자가 게시글을 조회한다면 5GiB의 메모리를 사용하게 된다.
사용할 수 있는 최대 메모리가 4GiB라면 OOM 에러가 발생할 수 있다.

대량으로 객체가 생성되는 것을 방지하려면 조회 범위를 제한해야 한다.
10년 치 거래 내역을 한버에 조회할 수 있도록 하기보다는 최대 3개월 치만 조회할 수 있도록 한다.
마찬가지로 한 번에 조회할 수 있는 데이터의 개수도 트래픽 규모와 메모리 크기에 맞춰 제한해야 한다.

파일 다운로드와 같은 기능을 구현할 때는 스트림을 활용한다.
다음 자바 코드 처럼 파일 데이터를 한꺼번에 메모리에 로딩한 후에 응답하는 방식은 피해야 한다.
파일 크기와 동시 사용자 수에 따라 메모리 사용량이 급증할 수 있기 때문이다.
이 코드는 30MiB 크기의 파일을 100명이 동시에 다운로드하면 3GiB의 메모리를 사용하게 된다.

```java
var bytes = Files.readAllBytes(Paths.get("file.txt")); // 파일을 한 번에 메모리에 로딩
out.write(bytes);
```

스트림을 활용하면 파일 처리 과정에서 필요한 메모리 크기를 줄일 수 있다. 다음은 스트림을 이용하도록 변환한 코드이다.

```java
InputStream in = Files.newInputStream(Paths.get("file.txt")); // 파일을 스트림으로 읽기
byte[] buffer = new byte[8192]; // 8KiB 버퍼

int read;
while ((read = in.read(buffer)) != -1) {
    out.write(buffer, 0, read); // 버퍼에 있는 데이터만 전송
}
```

이 코드는 파일을 한 번에 읽지 않고 8KiB씩 끊어 읽는다. 동시에 100명이 다운로드를 요청하더라도 메모리 사용량은 800KiB에 불과하다. 파일 전체를 한 번에 메모리에 로딩하는 방식은 3GiB의 메모리를 사용하지만 스트림을 이용하면 800KiB의 메모리만 사용한다. 이처럼 스트림을 활용하면 메모리 사용량을 줄일 수 있다.

> [!NOTE]
> 문제 원인을 분석하기 위해 힘 덤프를 저장하고 서버를 재시작했다.
>
> 엑셀 다운로드 기능을 실행 → 조회한 데이터가 수백만 건 → 모든 데이터가 메모리에 로딩됨  
> → 엑셀 생성 시간이 길어지자 사용자는 요청을 취소하고 다시 요청함  
> → OOM 발생

> **해결:**
>
> - 엑셀을 메모리에서 생성하지 않고 로컬 파일에 스트림 형태로 만들도록 변경
> - DB에서 조회한 결과를 리스트로 한 번에 받아 처리하던 것을 스트림 형태로 받아 순차적으로 처리하는 방식으로 변경

## 응답 데이터 압축

응답 시간에는 데이터 전송 시간이 포함된다. 이 전송 시간은 2가지 요인에 영향을 받는다.

- 네트워크 속도
- 전송 데이터 크기

사용자의 네트워크 속도가 느리면 응답 시간이 길어진다.
하나의 무선 공유기에 너무 많은 사용자가 붙었을 때 웹사이트가 느려지는 것과 같은 원리다.
전송할 데이터의 크기가 커도 응답 시간이 길어진다.
10KiB 크기의 파일을 다운로드받는 시간 보다 1GiB 크기의 파일을 다운로드받는 시간이 더 긴 것과 같다.

서버는 사용자즈이 네트워크 속도를 제어할 수 없지만 전송하는 데이터의 크기는 제어할 수 있다.
이때 사용할 수 있는 방법은 응답 데이터를 압축해서 전송하는 것이다.
실제로 gzip으로 압축하면 데이터 크기를 50% 이상 줄일 수 있다.
전송 크기가 줄어든 만큼 응답 시간도 줄어든다.
데이터 전송량을 줄이는 것은 응답 시간뿐만 아니라 비용에도 영향을 준다.
Nginx와 같은 웹 서버는 압축 기능을 제공하고 있으므로 약간의 설정만 추가하면 즉시 효과를 볼 수 있다.

> [!NOTE]
> 웹 브라우저나 HTTP 클라이언트는 Accept-Encoding 헤더를 통해 서버에 처리할 수 있는 압축 알고리즘을 알린다.
> 예를 들어, gzip, deflate 알고리즘을 사용해서 압축을 풀 수 있다면 다음과 같이 헤더를 설정한다.]
>
> ```text
> Accept-Encoding: gzip, deflate
> ```
>
> 웹 서버는 Accept-Encoding 헤더를 확인한 후 지원하는 압축 알고리즘으로 응답 데이터를 압축한다.
> 이때 사용된 압축 알고리즘은 Content-Encoding 헤더에 포함되어 응답된다.
>
> **📜 핵심 정리**
>
> - 압축은 가장 바깥 레이어에서 1회만 처리하는 것이 좋다.
> - 이중 압축 = 데이터 전송 효율성 ↓ + CPU 낭비 ↑ + 오류 ↑
> - Best case: Reverse Proxy 혹은 Load Balancer에서 압축 + 애플리케이션은 순수 데이터 전송

응답 데이터를 압축할 때는 다음과 같은 점을 고려해야 한다.

- html, css, js와 같은 텍스트 파일은 압축률이 높다. 반면 jpeg, zip 파일 처럼 이미 압축된 파일은 압축률이 낮다. 따라서 모든 파일에 압축을 적용하는 것보다는 텍스트 파일에만 압축을 적용하는 것이 좋다.
- 웹 서버(HAProxy, Nginx, etc.)에 압축을 적용했더라도 방화벽이 이를 해제해 응답할 수 있다.

## 정적 자원과 브라우저 캐시

서버는 2가지 종류의 데이터를 응답한다. 하나는 동적 데이터, 다른 하나는 정적 데이터다.
동적 자원은 브라우저가 요청할 때마다 결과가 바뀌는 데이터로 제품 목록 HTML 이나 제품 상세 JSON과 같은 데이터다.
정적 자원은 요청할 때마다 결과가 바뀌지 않는 데이터로 이미지, CSS, JS 파일과 같은 데이터다.
정적 자원은 전체 트래픽에서 상당한 비중을 차지한다. 이미지가 많은 온라인 쇼핑몰 사이트의 경우 전체 트래픽의 80%를 차지하기도 한다.

서버가 전송하는 트래픽을 줄이면서 브라우저가 정적 자원을 캐시할 수 있도록 설정하는 것이 좋다.
HTTP 프로토콜에서는 데이터를 응답할 때 Cache-Control 헤더를 통해 브라우저 캐시 설정을 지원한다.

```text
Cache-Control: max-age=60
```

## 정적 자원과 CDN

브라우저 캐시를 사용하면 네트워크 트래픽을 줄일 수 있지만, 브라우저 캐시는 브라우저 단위로 동작하기 때문에 동시에 많은 사용자가 요청할 경우 순간적으로 많은 양의 이미지, JS, CSS 파일을 전송하게 된다. 이로 인해 빠르게 네트워크가 포화되어 응답 시간이 급격하게 느려진다. 4차선 도로(대역폭)에 차가 1~2대씩 지나가면 막힘없이 잘 통과하지만 수십 대의 차가 몰리면 도로가 막히는 것과 같은 원리다.

이런 문제를 해결하는 방법 중 하나가 CDN(Content Delivery Network)이다.
이름에서 알 수 있듯이 CDN은 콘텐츠를 제공하기 위한 별도의 네트워크를 의미한다.
사용자는 CDN이 제공하는 서버에 요청을 보내고 CDN은 사용자의 요청을 처리하기 위해 가장 가까운 CDN 엣지 서버(Edge Server)에 요청을 전달한다.
CDN 서버에 요청한 콘텐츠가 없으면 오리진 서버(Origin Server)에서 콘텐츠를 가져온다.
오리진 서버에 읽어온 콘텐츠는 CDN 서버에 캐시된다.

## 대기 처리

사용자가 순간 폭증할 때가 있다. 대표적인 에가 콘서트 예매다.
이렇게 짧은 시간 동안 폭증하는 트래픽은 어떻게 처리해야 할까? 서버 증설, DB 증설 ...
짧은 시간을 버티기 위해서 투입해야 하는 비용이 크다.
또한 클라우드에서 증설한 서버는 다시 줄일 수 있지만 DB는 그렇지 않다. 최대 트래픽에 맞춰 DB 성능을 Scale Up하면 다시 DB 성능을 줄이기가 어렵다.
전체 서비스 시간 1%도 되지 않는 시간을 위해 고정 비용(DB 비용)이 커지는 격이다.

이런 문제를 해결하기 위해 대기 처리 시스템을 도입할 수 있다.
처리할 수 있는 시스템의 처리량을 무작정 늘리기보다는 수용할 수 있는 수준의 트래픽만 받아들이고 나머지는 대기 처리 하는 것이다.

> [!NOTE]
> 서버 개발자는 대규모 트래픽 대응을 위한 아키텍처 + 비용 절감 방안을 고민해야 한다.

# 3장. 성능을 좌우하는 DB 설계와 쿼리

## 성능에 핵심인 DB

DB 성능은 연동하는 모든 서버 성능에 영향을 준다.
쿼리 실행 시간이 길어지면서 전체 서비스가 느려지는 현상이 발생할 수 있다.

> [!NOTE]  
> **풀 스캔(Full Scan)**  
> 풀 스캔은 DB 테이블에 있는 모든 데이터를 읽는 것을 의미한다.
> 풀 스캔은 인덱스를 사용하지 않고 테이블에 있는 모든 데이터를 읽기 때문에 성능이 저하된다.
> 데이터 개수가 적을 때는 풀 스캔을 사용해도 성능에 큰 영향을 주지 않지만 데이터 개수가 많아지면 응답 시간이 기하급수적으로 늘어난다.

## 조회 트래픽을 고려한 인덱스 설계

DB 테이블 설계할 때는 조회 기능과 트래픽을 고려해야 한다.

풀 스캔이 발생하지 않도록 하려면 조회 패턴을 기준으로 인덱스를 설계해야 한다.
게시판의 경우 카테고리별로 게시글 목록을 조회하는 패턴이 존재하므로 category 컬럼에 인덱스를 추가해서 조회 성능을 개선할 수 있다.

> [!NOTE] > **전문 검색 인덱스**
>
> ```sql
> select * from article
> where content like '%검색어%'
> ```
>
> 그런데 중간에 포함된 단어를 검색하기 위한 Like 쿼리는 인덱스를 사용할 수 없다.
>
> 엘라스틱서치(Elasticsearch)와 같은 전문 검색 인덱스를 사용하면 풀 스캔을 피할 수 있다.
> 하지만 별도의 검색 엔진을 구성하기 힘든 상황이라면 DB에서 제공하는 전문 검색 기능을 사용할 수 있다.
> 예를 들어, Oracle Text나 MySQL의 FULLTEXT 인덱스를 사용하여 전문 검색을 지원한다.

### 단일 인덱스와 복합 인덱스

사용자의 모든 활동 내역을 보관하기 위해 activty_log 테이블을 설계했다고 가정하자.
일 평균 방문 회원이 10만 명이고, 평균 5번의 활동을 한다면, 한 달이면 1,500만 건의 로그가 쌓인다.

고객 센터에서 특정 사용자의 일자병 활동 내역을 조회하는 목적으로 activity_log 테이블을 사용한다고 가정하자.
다음 쿼리를 사용해서 활동 내역을 조회할 것이다.

```sql
SELECT * FROM activity_log
WHERE userId = 1234
AND activityDate BETWEEN '2025-05-01' AND '2025-05-18';
```

- 단일 인덱스: userId만 인덱스를 사용
- 복합 인덱스: (userId, activityDate)를 인덱스로 사용

사용자당 가질 수 있는 데이터가 얼마나 될지 가늠해보면 어떤 인덱스를 사용해야 할지 판단하는 데 도움이 된다.
데이터가 많지 않다면 단일 인덱스를 사용해도 성능에 큰 영향을 주지 않는다.
하지만 사용자당 수만 건이 넘는 데이터가 쌓일 수 있다면, 복합 인덱스를 사용해야 한다.

```sql
select activityDate, activityType, count(activityType)
from activity_log
where activityDate = '2025-05-01'
group by activityType
```

인덱스가 (activityDate, activityType) 순서로 되어 있으면, 인덱스 자체가 이미 activityDate별로 정렬되어 있고, 그 안에서 activityType별로도 정렬되어 있습니다. MySQL(혹은 다른 RDBMS)이 인덱스만 읽으면서 바로 그룹핑/집계를 할 수 있습니다. 즉, 인덱스 스캔만으로 결과를 빠르게 만들 수 있습니다.

그렇기에 해당 쿼리에서는 복합 인덱스가 유리합니다.

### 선택도를 고려한 인덱스 컬럼 선택

인덱스를 생성할 때는 선택도(Selectivity)를 고려해야 한다.
선택도는 인덱스에서 특정 컬럼의 고유한 값 비율을 의미한다.
선택도가 높으면 해당 컬럼에 고유한 값이 많다는 뜻이며, 선택도가 낮으면 고유한 값이 적다는 뜻이다.
선택도가 높을수록 인덱스를 이용한 조회 효율이 높아진다.

아래의 회원 테이블을 보자.

```sql
CREATE TABLE member (
    id INT NOT NULL PRIMARY KEY,
    gender char(10),
    ... 생략
);
```

gender 컬럼은 MALE, FEMALE, NOT_SPECIFIED 3개 값 중 하나를 갖고, gender 컬럼을 인덱스로 사용한다고 하자.
전체 회원 데이터 중 MALE 50만 개, FEMALE 50만 개, NOT_SPECIFIED이 천 개일 때 다음 쿼리를 실행하면 여전히 50만 개의 데이터를 확인해야 한다. 선택도가 낮아 인덱스 효율이 떨어진다.

```sql
select * from member
where gender = 'FEMALE' and birthyear = 1997;
```

인덱스로 사용할 컬럼이 선택도가 항상 높아야 하는 것은 아니다.

```sql
CREATE TABLE member (
    id INT NOT NULL PRIMARY KEY,
    `status` char(10) not null,
);
```

status 컬럼은 WAITING, PROCESSING, COMPLETED 3개 값 중 하나를 갖고, status 컬럼을 인덱스로 사용한다고 하자.
선택도가 낮은 컬럼에도 불구하고 인덱스를 사용하면 풀 스캔을 방지할 수 있다.

### 커버링 인덱스 활용하기

커버링 인덱스는 특정 쿼리를 실행하는데 필요한 컬럼을 모두 포함하는 인덱스를 말한다.
커버링 인덱스를 사용하면 쿼리 실행 효율을 높일 수 있다.
예를 들어 다음 쿼리를 실행한다고 해보자.

```sql
select * from activity_log
where activityDate = '2025-05-01' and activityType = 'VISIT';
```

(activityDate, activityType) 컬럼을 사용하는 인덱스가 있다면, 인덱스를 사용해서 데이터를 빠르게 선택할 수 있다.
데이터를 선택한 뒤에는 컬럼값을 조회하기 위해 각 데이터를 디스크에서 읽어 온다.
인덱스를 사용해서 조회할 데이터를 선택하는 과정은 빠르지만 실제 데이터 자체는 읽어와야 하는 것이다.

이번에는 다음 쿼리를 보자.

```sql
select activityDate, activityType
from activity_log
where activityDate = '2025-05-01'
group by activityType;
```

(activityDate, activityType) 인덱스가 있다면, 인덱스를 사용해서 데이터를 빠르게 선택할 수 있다.
왜냐하면 쿼리를 실행하는데 필요한 activityDate, activityType 컬럼이 모두 인덱스에 포함되어 있기 때문이다.
실제 데이터 읽어오는 과정이 생략되므로 쿼리 실행 시간이 빨라진다.

### 인덱스는 필요한 만큼만 만들기

효과가 적은 인덱스를 추가하면 오히려 성능이 나빠질 수 있다.
인덱스는 조회 속도를 빠르게 해주지만 데이터 추가, 변경, 삭제 시에는 인덱스 관리에 따른 비용이 추가되기 때문이다.
또한 인덱스 자체도 데이터이기 때문에 인덱스가 많아질수록 메모리와 디스크 사용량도 함께 증가한다.

## 몇 가지 조회 성능 개선 방법

### 미리 집계하기

다음 기능을 제공하는 간단한 설문 조사 기능을 만든다고 하자.

- 각 설문은 질문이 4개로 고정되어 있다.
- 회원은 각 설문 조사마다 '좋아요'를 할 수 있다.
- 설문 조사 목록을 보여줄 때 답변 수와 '좋아요' 수를 함께 보여준다.

```memaid
---
title: 간단한 설문 조사 기능을 위한 테이블 설계
---

erDiagram
    direction LR
    survey ||--o{ answer : ""
    survey ||--o{ liked : ""
    survey {
        integer(10) surveyId
        varchar(100) subject
        date from
        date to
        varchar(255) question1
        varchar(255) question2
        varchar(255) question3
        varchar(255) question4
    }
    answer {
        integer(10) surveyId
        integer(10) memberId
        varacher(100) answer1
        varacher(100) answer2
        varacher(100) answer3
        varacher(100) answer4
    }
    liked {
        integer(10) surveyId
        integer(10) memberId
    }
```

목록을 표시할 때 설문에 답변한 회원 수와 '좋아요' 수를 함께 보여줘야 한다.

```sql
select
  surveyId,
  subject,
  (select count(*) from answer where surveyId = s.surveyId) as answerCount,
  (select count(*) from liked where surveyId = s.surveyId) as likeCount
from survey
order by surveyId desc
limit 30
```

30개의 설문이 있을 때 설문마다 평균 답변자 수가 10만 명이고, '좋아요'를 한 회원 수가 1만 명이라고 가정해보자.
위 쿼리를 실행하면 논리적으로 다음 쿼리가 실행된다.

- 목록 조회 1번
- 답변자 수를 세는 쿼리 30번: select 쿼리가 30 개의 설문 데이터를 조회하므로 각 설문마다 답변자 수를 구하기 위한 서브 쿼리가 30번 실행된다. 각 쿼리는 10만 개를 센다.
- '좋아요' 수를 세는 쿼리 30번: select 쿼리가 30 개의 설문 데이터를 조회하므로 각 설문마다 '좋아요' 수를 구하기 위한 서브 쿼리가 30번 실행된다. 각 쿼리는 1만 개를 센다.

합치면 논리적으로 61번의 쿼리가 실행된다.
목록 조회 쿼리는 0.01초, 답변자를 세는 서브 쿼리가 설문당 0.1초, '좋아요' 수를 세는 서브 쿼리가 설문당 0.05초 걸린다고 할 경우 목록을 조회하는 데 걸리는 시간은 다음과 같다.

- 쿼리 시간 = 0.01 + 0.1*30 + 0.05*30 = 4.51초

비 정규화 방식으로 푸는 방법과 한 방쿼리를 여러 번의 쿼리로 나누는 방법이 있다.

비정규화 없이 데이터 구조가 단순함, 항상 최신 데이터를 반영하는 여러 번위 쿼리로 나누는 방법으로 해결해보자.

```sql
select
  surveyId,
  subject,
from survey
order by surveyId desc
limit 30
```

```sql
select surveyId, count(*) as answerCount
from answer
where surveyId in (:surveyIds)
```

```sql
select surveyId, count(*) as likeCount
from liked
where surveyId in (:surveyIds)
```

그럼에도 불구하고 1~2초 정도의 집계 지연이내가 필요하다면 비정규화 방식으로 해결할 수 있다.

```mermaid
---
title: 집계 값을 저장할 컬럼을 활용해 조회 성능을 개선할 수 있다.
---

erDiagram
    direction LR
    survey {
        integer(10) surveyId
        varchar(100) subject
        date from
        date to
        varchar(255) question1
        varchar(255) question2
        varchar(255) question3
        varchar(255) question4
        integer(10) answerCount
        integer(10) likeCount
    }
```

**1. 직접 DB 쿼리 업데이트 하기**

```sql
-- answer 테이블에 답변을 추가한다.
insert into answer values (...);

-- survey 테이블의 answerCount를 1 증가시킨다.
update survey set answerCount = answerCount + 1 where surveyId = :surveyId;

-- liked 테이블에 '좋아요'를 추가한다.
insert into liked values (...);

-- survey 테이블의 likeCount를 1 증가시킨다.
update survey set likeCount = likeCount + 1 where surveyId = :surveyId;
```

**2. 이벤트 발행**

```java
// 답변 저장 서비스
@Service
public class AnswerService {
    private final ApplicationEventPublisher eventPublisher;
    private final AnswerRepository answerRepository;

    public AnswerService(ApplicationEventPublisher eventPublisher, AnswerRepository answerRepository) {
        this.eventPublisher = eventPublisher;
        this.answerRepository = answerRepository;
    }

    @Transactional
    public void submitAnswer(Long surveyId, Long memberId, String answer1, String answer2, String answer3, String answer4) {
        Answer answer = new Answer(surveyId, memberId, answer1, answer2, answer3, answer4);
        answerRepository.save(answer);

        // 비동기 집계 이벤트 발행
        eventPublisher.publishEvent(new AnswerSubmittedEvent(surveyId));
    }
}

// 비동기 집계 이벤트 리스너
@Component
public class SurveyAnswerCountUpdater {
    private final SurveyRepository surveyRepository;
    private final AnswerRepository answerRepository;

    public SurveyAnswerCountUpdater(SurveyRepository surveyRepository, AnswerRepository answerRepository) {
        this.surveyRepository = surveyRepository;
        this.answerRepository = answerRepository;
    }

    @Async // 별도의 스레드에서 비동기로 처리된다.
    @EventListener
    public void handleAnswerSubmitted(AnswerSubmittedEvent event) {
        Long surveyId = event.getSurveyId();
        long count = answerRepository.countBySurveyId(surveyId);
        surveyRepository.updateAnswerCnt(surveyId, count);
    }
}
```

## 알아두면 좋을 몇 가지 주의 사항

### 쿼리 타임아웃

동시 사용자가 증가할 때 응답 시간이 길어지면 그에 반비례해 처리량은 감소한다.
하지만 단순히 처리량만 떨어지는 데서 끝나지 않는다.
예를 들어, 동시 접속이 증가하면서 특정 쿼리의 실행 시간이 15초 이상으로 늘어났다고 해보자.
사용자는 몇 초만 지나도 서비스가 느끼고 다시 몇 초 후에 재시도를 하게 된다.
이런식으로 재시도가 반복되면 동시에 처리해야 하는 요청 수가 기하급수적으로 늘어나고 서버 부하는 폭증하게 된다.

이런 상황을 방지하는 방법 중 하나는 쿼리 실행 시간을 제한(타임아웃) 설정 하는 것이다.
사용자는 에러 화면을 보게 되지만 서버 입장에서는 해당 요청을 정상적으로 종료(처리)한 셈이다.

쿼리 타임아웃은 서비스와 기능의 특성에 따라 다르게 설정해야 한다.
예를 들어, 실시간으로 처리해야 하는 서비스는 1초 이내로 설정하고, 상품 결제 기능은 보다 긴 타임아웃이 필요하다.

### 상태 변경 기능은 복제 DB에서 조회하지 않기

첫째, 주 DB와 복제 DB의 데이터가 일치하지 않을 수 있다. 주 DB에서 변경된 데이터는 다음 두 단계를 거쳐 복제 DB에 반영된다.

- 네트워크를 통해 복제 DB에 전달
- 복제 DB는 자체 데이터에 변경 내용을 반영

둘째, 트랜잭션 문제가 발생할 수 있다. 주 DB와 복제 DB 간 데이터 복제는 트랜잭션 커밋 시점에 이뤄진다.
주 DB의 트랜잭션 범위 내에서 데이터를 변경하고, 복제 DB에서 변경 대상이 될 수 있는 데이터를 조회하면 데이터 불일치로 인해 문제가 생긴다.

### 배치 쿼리 실행 시간 증가

배치에서 사용하는 쿼리의 실행 시간을 지속적으로 추적해야 한다.
데이터를 일정 크기로 나눠 처리하는 것도 좋다.

### 타입이 다른 컬럼 조인 주의

```mermaid
---
title: 다른 타입끼리 조인할 때 생기는 문제
---

erDiagram
    direction LR
    user ||--o{ push : ""
    user {
        integer(10) userId
        integer(10) name
    }
    push {
        integer(10) pushId
        varchar(30) receiverId
        varchar(2) receiverType
    }
```

```sql
select u.userId u.name, p.*
from user u, push p
where u.userId = p.receiverId and p.receiverType = 'USER';
```

타입이 다른 두 컬럼의 조인을 할 때 컬럼의 값을 비교하는 과정에서 DB는 타입 변환을 수행한다.
userId는 INT 타입이고 receiverId는 VARCHAR(30) 타입이므로 DB는 VARCHAR(30) 타입을 INT 타입으로 변환한다.

```sql
select u.userId u.name, p.*
from user u, push p
where cast(u.userId as char character set utf8mb4 collate 'utf8mb4_unicode_ci' = p.receiverId
and p.receiverType = 'USER';
```

> [!NOTE]
> 문자열 타입을 비교할 때는 컬럼의 캐릭터셋이 같은지 확인해야 한다.
> 캐릭터셋이 다르면 DB는 캐릭터셋을 변환하는 과정에서 성능이 저하된다.

### 테이블 변경은 신중하게

테이블 변경 시 주의해야 하는 이유는 DB의 테이블 변경 방식 때문이다.
예를 들어, MySQL은 테이블을 변경할 떄 새 테이블을 생성하고 원본 테이블의 데이터를 복사한 뒤, 복사가 완료되면 새 테이블로 대체한다.
이 복사 과정에서는 UPDATE, INSERT, DELETE 같은 DML 작업을 허용하지 않기 때문에 복사 시간만큼 서비스가 멈춘다.

### DB 최대 연결 개수

- API 서버는 세 대다
- 트래픽이 증가하고 있어 수평 확장이 필요하다.
- DB 서버의 CPU 사용률은 20% 수준으로 여유가 있다.

트래픽이 증가를 감당하기 위해 API 서버를 추가할 수 있다.
그런데 새로 추가한 API 서버에서 DB 커넥션 생성에 실패한다면 무엇이 문제일까.
DB 서버 자원에는 여유가 있지만 API 서버에서 DB 연결되지 않는다면 DB에 설정된 최대 연결 개수를 확인해야 한다.

예를 들어 DB의 최대 연결 개수가 100개라고 가정하자.
API 서버의 커넥션 풀 개수가 30개일 때 API 서버를 네 대로 늘리면 필요한 커넥션 수는 120개다.
하지만 DB의 최대 연결 개수는 100개까지만 연결을 허용하므로 20개의 커넥션을 얻지 못하고 연결 실패가 발생하게 된다.
이 경우에는 DB의 최대 연결 개수를 늘려주는 것만으로도 해결할 수 있다.

단 주의할 점이 있다. DB 서버의 CPU 사용률이 70% 이상으로 높다면 연결 개수를 늘리면 안된다.
연결 수가 많아질수록 DB 부하는 증가하고 성능 저하가 발생할 수 있다.
이번 경우에는 먼저 캐시 서버 구성이나 쿼리 튜닝 같은 조치를 통해 DB 부하를 낮추고 필요할 때 연결 개수를 늘려야 한다.

## 실패와 트랜잭션 고려하기

```java
@Transactional
void signup(SignupRequest request) {
  // ...
  // 회원 가입
  memberRepository.save(request.toMember());

  // 이메일 발송
  try {
    mailSender.sendEmail(...);
  } catch (Exception e) {
    // 메일 발송 오류 무시
    // 로그를 기록해 모니터링
  }
}
```

# 4장. 외부 연동이 문제일 때 살펴봐야 할 것들

## 타임아웃

![alt text](/public/images/주니어_백엔드_개발자가_반드시_알아야_할_실무_지식_1.svg)

이런 문제를 완화할 수 있는 방법 중 하나는 연동에 대해 타임아웃을 지정한는 것이다.
A 서비스에서 B서비스로 요청을 보낼 때 B API 타임아웃을 걸어, 이후 B 서비스에서 응답이 오지 않더라도 A 서비스는 계속해서 요청을 처리할 수 있도록 하는 것이다.

### 2가지 타임아웃: 연결 타임아웃, 읽기 타입아웃

```mermaid
---
title: 간략하게 표시한 두 서비스 간 통신 과정
---

sequenceDiagram
    autonumber
    participant A as A 서비스
    participant B as B 서비스

    A->>B: 연결 시도
    activate A
    activate B
    B-->>A: 연결 성공
    deactivate B
    A->>B: 요청 전송
    activate B
    B-->>A: 응답 전송
    deactivate B
    A->>B: 연결 종료
    deactivate A
    activate B
    deactivate B
```

첫 번째 단계는 네트워크 연결 시도 단계다.
네트워크 상황이나 연결할 서버의 상태에 따라 연결에 오랜 시간이 걸릴 수 있다.
연결에 시간이 오래 걸리면 대기 시간도 함께 증가한다.
대기 시간이 무한정 길어지면 성능 문제가 발생하므로, 연결 타임아웃(connection timeout)을 설정해 대기 시간을 제한 해야 한다.

응답을 받기까지 시간이 오래 걸리면 앞서 말한 대기 시간 문제가 다시 발생한다. 따라서 읽기 타임아웃(read timeout)을 설정해 응답 대기 시간을 제한해야 한다.

처음 연동하는 서비스라면 타임아웃 시간을 아래와 같이 설정한 뒤, 추이를 보면서 조정하는 것이 좋다.

- 연결 타임아웃: 3 ~ 5초
- 읽기 타임아웃: 5 ~ 30초

읽기 타임아웃이 다소 길게 느껴질 수 있다.
하지만 처음부터 1~3초 정도로 짧게 설정하면 타임아웃 에러가 자주 발생할 수 있다.
게다가 타임아웃 시간이 너무 짧으면 연동 서비스가 정상처리했음에도 불구하고 타임아웃 에러가 발생할 수 있다.

```mermaid
---
title: 타임아웃이 짧으면 정상 처리도 에러가 될 수 있다.
---

sequenceDiagram
  Actor User as User
  participant Commerce as 커머스 서버
  participant PG as PG 서버
  participant Card as 카드사

  User ->> Commerce: 1. 상품 결제
  Commerce ->> PG: 2. 승인 요청
  PG ->> Card: 3. 카드 승인
  PG -->> Commerce: 4. 타임아웃(5초)
  Commerce -->> User: 5. 실패 응답
  Card -->> PG: 6. 승인 성공(10초)
```

이 과정이 끝나면 고객의 카드로는 결제했지만 상품은 구매하지 못하는 불쾌한 상황에 빠진다.
커머스 서버가 PG 서버와의 통신에서 타임아웃을 15초로 설정했다면 발생하지 않았을 문제다.
결제처럼 민감한 기능은 읽기 타임아웃 시간을 약간 길게 설정해서 간헐적으로 연동 시간이 길어지더라도
정상적으로 처리할 수 있어야 한다.

**코드로 해당 상황 해결을 생각해보자.**

1. 결제 요청 응답 상태 테이블 설계

```java
@Entity
public class Payment {
    @Id @GeneratedValue
    private Long id;

    private String orderId;
    private String paymentKey; // PG사 결제 키
    private PaymentStatus status; // REQUESTED, SUCCESS, FAIL, PENDING

    private LocalDateTime requestedAt;
    private LocalDateTime completedAt;
    // ... 기타 필드
}

public enum PaymentStatus {
    REQUESTED, SUCCESS, FAIL, PENDING, REFUNDED
}
```

2. 결제 요청 서비스(타임아웃/에러 처리))

```java
@Service
public class PaymentService {
    private final PaymentRepository paymentRepository;
    private final PgClient pgClient;
    private final ApplicationEventPublisher eventPublisher;

    public PaymentService(PaymentRepository paymentRepository, PgClient pgClient, ApplicationEventPublisher eventPublisher) {
        this.paymentRepository = paymentRepository;
        this.pgClient = pgClient;
        this.eventPublisher = eventPublisher;
    }

    @Transactional
    public PaymentResponse pay(String orderId, PaymentRequestDto requestDto) {
        Payment payment = new Payment();
        payment.setOrderId(orderId);
        payment.setStatus(PaymentStatus.REQUESTED);
        payment.setRequestedAt(LocalDateTime.now());
        paymentRepository.save(payment);

        try {
            // PG 승인 요청 (타임아웃 15초)
            PgResponse pgResponse = pgClient.approve(requestDto, 15_000);

            if (pgResponse.isSuccess()) {
                payment.setStatus(PaymentStatus.SUCCESS);
                payment.setPaymentKey(pgResponse.getPaymentKey());
                payment.setCompletedAt(LocalDateTime.now());
                paymentRepository.save(payment);
                return PaymentResponse.success();
            } else {
                payment.setStatus(PaymentStatus.FAIL);
                paymentRepository.save(payment);
                return PaymentResponse.fail("결제 실패");
            }
        } catch (TimeoutException e) {
            // 타임아웃 발생: 상태를 PENDING으로 두고, 결과 조회 이벤트 발행
            payment.setStatus(PaymentStatus.PENDING);
            paymentRepository.save(payment);

            // 비동기 결제 결과 조회 이벤트 발행
            eventPublisher.publishEvent(new PaymentPendingEvent(payment.getId()));

            return PaymentResponse.fail("결제 결과 확인 중입니다. 잠시 후 알림을 확인해 주세요.");
        }
    }
}
```

3. 비동기 결제 결과 조회 서비스

```java
@Component
public class PaymentPendingEventListener {
    private final PaymentRepository paymentRepository;
    private final PgClient pgClient;
    private final NotificationService notificationService;

    public PaymentPendingEventListener(PaymentRepository paymentRepository, PgClient pgClient, NotificationService notificationService) {
        this.paymentRepository = paymentRepository;
        this.pgClient = pgClient;
        this.notificationService = notificationService;
    }

    @Async
    @EventListener
    public void handlePaymentPending(PaymentPendingEvent event) {
        Payment payment = paymentRepository.findById(event.getPaymentId()).orElseThrow();

        // 3회까지 5초 간격으로 결과 조회 시도
        for (int i = 0; i < 3; i++) {
            try {
                Thread.sleep(5000);
                PgResult result = pgClient.queryResult(payment.getOrderId());

                if (result.isSuccess()) {
                    payment.setStatus(PaymentStatus.SUCCESS);
                    payment.setCompletedAt(LocalDateTime.now());
                    paymentRepository.save(payment);
                    notificationService.notifySuccess(payment.getOrderId());
                    return;
                } else if (result.isFail()) {
                    payment.setStatus(PaymentStatus.FAIL);
                    paymentRepository.save(payment);

                    // 보상 트랜잭션(환불 처리 이벤트 발행)
                    eventPublisher.publishEvent(new PaymentCompensateEvent(payment.getOrderId()));

                    notificationService.notifyFail(payment.getOrderId());
                    return;
                }
            } catch (Exception e) {
                // 로깅 등
            }
        }
        // 3회 시도 후에도 결과 미확정 시, 관리자 알림 등 추가 처리
    }
}
```

```java
@Service
public class CompensationService {
    private final PaymentRepository paymentRepository;
    private final PgClient pgClient;

    @Transactional
    public void compensateIfNeeded(String orderId) {
        Payment payment = paymentRepository.findByOrderId(orderId)
            .orElseThrow();

        if (payment.getStatus() == PaymentStatus.SUCCESS && !상품_지급_완료(orderId)) {
            // 결제는 성공했으나 상품 미지급 → 환불 시도
            pgClient.refund(payment.getPaymentKey());
            payment.setStatus(PaymentStatus.REFUNDED);
            paymentRepository.save(payment);
        }
    }
}
```

4. 클라이언트
   1. 결제 결과 대기 화면에서: "결제 결과를 확인 중입니다."
   2. 주기적 폴링: "결제 결과를 확인 중입니다." (서버에서 결제 결과 상태 조회 API 제공 해야함)

### 타임아웃간의 차이 정리

- 연결 타임아웃: 서버와 연결을 맺는 데 걸리는 최대 시간
- 읽기 타임아웃:
  응답의 첫 바이트를 기다리는 시간
  서버가 연결은 됐지만, 응답을 늦게 보내거나 서버 내부 처리 지연이 있을 때 발생
- 소켓 타임아웃:
  응답 중간에 데이터가 오지 않을 때의 최대 대기 시간 (실제로는 읽기 타임아웃과 거의 동일하게 동작)  
  응답 중간에 데이터가 끊기면(서버가 chunked 응답을 보내다가 중간에 멈춤, 네트워크 중간에 끊김) 발생

```java
RequestConfig config = RequestConfig.custom()
    .setConnectTimeout(5000)      // 연결 타임아웃 (ms)
    .setConnectionRequestTimeout(5000) // 커넥션 풀에서 커넥션을 얻을 때까지 대기 시간
    .setSocketTimeout(10000)      // 소켓(읽기) 타임아웃 (ms)
    .build();

CloseableHttpClient client = HttpClients.custom()
    .setDefaultRequestConfig(config)
    .build();

HttpComponentsClientHttpRequestFactory factory = new HttpComponentsClientHttpRequestFactory(client);
RestTemplate restTemplate = new RestTemplate(factory);
```

## 재시도

```mermaid
---
title: 재시도를 통한 오류 대응
---

sequenceDiagram
  participant A as A 서비스
  participant B as B 서비스

  A ->> B: 1. API 호출
  B -->> A: 1.1 타임아웃 에러

  A ->> B: 2. API 재호출
  B -->> A: 2.1 성공 응답
```

### 재시도 가능 조건

재시도를 통해 연동 실패를 줄일 수 있지만, 항상 재시도를 할 수 있는 것은 아니다.
연동 API를 다시 호출해도 되는 조건인지 확인해야 한다.

예를 들어 포인트 서비스가 제공하는 API를 호출해 포인트를 차감하는 상황을 생각해보자.
포인트 서비스를 호출하는 과정에서 **읽기 타임아웃**이 발생했을 때 재시도를 하게 되면 포인트 차감이 두 번 발생할 수 있다.

```mermaid
---
title: 재시도해도 문제가 없는 경우에만 재시도를 시도해야 한다.
---

sequenceDiagram
  autonumber
  participant order as 주문 서비스
  participant point as 포인트 서비스

  order->>+point: 포인트 차감
  point-->>order: 읽기 타임아웃 에러
  point->>-point: 포인트 차감 처리


  order->>+point: 포인트 차감 재호출
  point->>point: 포인트 차감 처리
  point-->>-order: 성공 응답
```

재시도를 해도 되는 조건은 다음 3가지로 정리할 수 있다.

- 단순 조회
- 연결 타임아웃
- 멱등성(idempotent)을 가진 변경 기능

읽기 타임아웃은 재시도할 때 주의해야 한다. 이 경우는 이미 연동 서비스가 요청을 처리하고 있는 중이기 때문이다.
읽기 타임아웃이 발생한 상황에서 재시도를 하면 포인트가 중복 차감되는 데이터 문제가 생길 수 있다.

상대를 변경하는 연동 API를 재시도할 때는 멱등성을 고려해야 한다. 멱등성이란 연산을 여러번 적용해도 결과가 달라지지 않는 성질을 말한다. 에를 들어, 좋아요 버튼을 클릭하는 API는 멱등성을 가진다.

한 사용자가 좋아요 버튼을 클릭하면 좋아요 수가 1 증가한다. 하지만 다시 클릭해도 좋아요 수는 1로 유지된다. 즉, 여러 번 클릭해도 결과는 같다는 것이다.

> [!TIP]
> 같은 API라도 실패 원인에 따라 재시도 여부를 결정해야 한다.
> 검증 오류가 발생한 경우에는 재시도를 해도 의미가 없다.

### 재시도 횟수와 간격

재시도를 무한정 할 수는 없다. 재시도 횟수만큼 응답 시간도 함께 늘어나기 때문이다.
대부분의 경우 1~2번의 정도의 재시도가 적당하다.
2번 재시도를 하면 총 3번 시도한 것이 되는데, 이 모두 실패한다면 간헐적인 오류보다는 다른 근본적인 문제일 가능성이 높다.

재시도 간격도 중요하다. 네트워크 연결 상태가 6초간 좋지 않은 상황을 가정해보자.
여러 차례 재시도 할 때는 재시도 간격을 점진적으로 늘리기도 한다.

### 재시도 폭풍(Retry Storm) 안티패턴

재시도를 통해 성공 가능성을 높일 수 있지만, 반대로 연동 서비스에는 더 큰 부하를 줄 수 있다.
읽기 타임아웃이 발생한 경우, 재시도를 통해 연동 서비스에 부하를 줄 수 있다.
따라서 재시도를 검토할 때는 연동 서비스의 성능 상황도 함께 고려해야 한다.

## 동시 요청 제한

A 서비스가 B 서비스에 의존하고,B 서비스가 동시 요청 100개까지 처리 가능할 때 A 서비스의 동시 요청이 300개라면
A 서비스도 B 서비스에 대한 동시 요청을 100개로 제한해야 하는지에 대한 고민이 된다.

A 서비스가 300개 동시 요청을 그대로 B 서비스에 전달하면 B 서비스는 100개만 정상 처리, 나머지는 대기/실패/타임아웃이 발생할 수 있습니다. 즉 전체 장애, 타임아웃, 큐 부하가 발생할 수 있습니다.

```java
@Bulkhead(name = "bServiceBulkhead", type = Bulkhead.Type.SEMAPHORE)
@RateLimiter(name = "bServiceRateLimiter")
public Response callBService(Request req) {
    return bServiceClient.call(req);
}
```

```yaml
// application.yml
// 동시에 100개 요청, 초과 요청은 최대 5초 대기 후 에러
resilience4j:
  bulkhead:
    instances:
      bServiceBulkhead:
        maxConcurrentCalls: 100
        maxWaitDuration: 5s

// 1초에 100건까지만 허용, 초과 요청은 최대 5초 대기 후 에러
resilience4j:
  ratelimiter:
    instances:
      bServiceRateLimiter:
        limitForPeriod: 100
        limitRefreshPeriod: 1s
        timeoutDuration: 5s
```

```java
// Reactor의 flatMap(concurrency) 활용
Flux.fromIterable(requests)
    .flatMap(req -> callBService(req), 100) // 동시 100개 제한
    .subscribe();
```

- application.yml에서 maxConcurrentCalls: 100 설정

제한하지 않으면, B 서비스 장애 → A 서비스 장애 → 전체 장애로 확산될 수 있다.

## 서킷 브레이커

서킷 브레이커는 누전 차단기와 비슷하게 동작한다. 과전류가 흐르면 차단기가 내려가 전기를 끊는 것처럼,
서킷 브레이커도 과도한 오류가 발생하면 연동을 중지시키고 바로 에러를 응답한다.

서킷 브레이커는 닫힘(closed), 열림(open), 반전(half-open) 세 가지 상태로 나뉜다.

![alt text](/public/images/주니어_백엔드_개발자가_반드시_알아야_할_실무_지식_2.svg)

보통 임계치는 다음 조건 중 하난를 사용한다.

- 시간 기준 오류 발생 비율: 예) 10초 동안 오류 비율이 50% 초과
- 개수 기준 오류 발생 비율: 예) 100개 요청 중 오류 비율이 50% 초과

열림 상태가 되면 연동 요청은 수행하지 않고, 바로 에러 응답을 리턴한다.
열림 상태는 지정된 시간 동안 유지된다.
이 시간이 지나면 반 열림 상태로 전환된다.
반 열림 상태에서는 일부 요청에 한해 연동 요청을 시도한다.
일정 개수 또는 일정 시간 동안 반 열림 상태를 유지하며, 이 기간 동안 연동에 성공하면 다시 닫힘 상태로 전환된다.

서킷 브레이커가 열려 있는 동안은 연동 서비스에 요청이 전달되지 않기 때문에 연동 서비스가 과부화 상황에서 벗어날 수 있는 기회도 생긴다.

## 외부 연동과 DB 연동

### 외부 연동과 트랜잭션 처리

- 외부 연동에 실패했을 때 트랜잭션을 롤백
- 외부 연동은 성공했지만 DB 연동에 실패해 트랜잭션을 롤백

**외부 연동에 실패했을 때 트랜잭션을 롤백**

```mermaid
---
title: 외부 연동에 실패하면 트랜잭션을 롤백
---

sequenceDiagram
  autonumber
  participant a_service as A 서비스
  participant a_db as A DB
  participant b_service as B 서비스

  a_service->>a_db: 트랜잭션 시작
  activate a_db
  deactivate a_db

  a_service->>a_db: 데이터 변경
  activate a_db
  deactivate a_db

  a_service->>+b_service: API 호출
  b_service-->>-a_service: 에러 응답

  a_service->>a_db: 트랜잭션 롤백
  activate a_db
  deactivate a_db
```

하지만 읽기 타임아웃이 발생해 트랜잭션을 롤백할 때는, 외부 서비스가 실제로는 성공적으로 처리했을 가능성을 염두에 두어야 한다.

```mermaid
---
title: 읽기 타임아웃 에러가 발생할때는 외부 연동이 성공했을 가능성도 고려해야 한다.
---

sequenceDiagram
  autonumber
  participant order_service as 주문 서비스
  participant order_db as 주문 DB
  participant point_service as 포인트 서비스

  order_service ->> order_db: 트랜잭션 시작
  activate order_db
  order_service ->> order_db: 주문 데이터 저장
  deactivate order_db

  order_service ->>+ point_service: 포인트 차감 API
  point_service -->> order_service: 읽기 타임아웃 에러
  point_service ->>- point_service: 포인트 차감 처리

  order_service ->> order_db: 트랜잭션 롤백
  activate order_db
  deactivate order_db
```

트랜잭션을 롤백했는데 외부 서비스가 실제로는 성공했을 경우, 두 가지 방법 중 하나를 검토해야 한다.
첫 번째는 일정 주기로 두 시스템의 데이터가 일치하는지 확인하고 보정하는 방법이다.
예를 들어, 주문 서비스와 포인트 서비스가 하루에 한 번씩 전날 포인트 사용 내역을 비교해 불일치 건이 있는지 확인하는 식이다.
불일치 건이 발견되면 수동으로 또는 자동으로 보정한다.

두 번째는 성공 확인 API를 호출하는 방식이다. 읽기 타임아웃이 발생한 경우, 일정 시간 후에 이전 호출이 실제로 성공했는지 확인하는 API를 호출한다.
이때 성공 응답이 오면 트랜잭션을 지속하고, 실패 응답이 오면 트랜잭션을 롤백한다. 이 방식은 연동 서비스가 성공 여부를 알려주는 API를 제공할 때만 사용할 수 있다.

이 방식의 변형으로 취소 API를 호출하는 방법도 있다. 읽기 타임아웃이 발생한 뒤 일정 시간후에 취소 API를 호출하는 것이다.
연동 서비스는 취소할 대상이 있으면 취소 처리를 수행한뒤 성공 응답을 주고, 취소할게 없다면 아무 동작 없이 성공 응답만 반환한다.

두 시스템 간 데이터 일관성이 중요한 기능이라면 정기적으로 데이터 일치를 확인하는 프로세스를 갖추는 것이 바람직하다.

### 외부 연동은 성공했는데 DB 연동에 실패해서 트랜잭션을 롤백

```mermaid
---
title: 외부 연동에 성공했는데 DB 처리에 실패했다면 트랜잭션을 롤백한 뒤 취소 API를 호출한다.
---

sequenceDiagram
  autonumber
  participant order_service as 주문 서비스
  participant order_db as 주문 DB
  participant point_service as 포인트 서비스

  order_service ->> order_db: 트랜잭션 시작
  activate order_db
  order_service ->> order_db: 주문 데이터 저장
  deactivate order_db

  order_service ->>+ point_service: 포인트 차감 API
  point_service ->>- order_service: 포인트 차감 성공

  order_service ->> order_db: 트랜잭션 커밋 시도
  activate order_db
  order_db -->> order_service: 트랜잭션 커밋 실패
  order_service ->> order_db: 트랜잭션 롤백
  deactivate order_db

  order_service ->> point_service: 포인트 차감 취소 API
  activate point_service
  deactivate point_service
```

취소 API가 없거나 취소에 실패할 수도 있기 때문에 데이터 일관성이 중요한 서비스라면 일정 주기로 데이터가 맞는지 비교하는 프로세스를 갖추는 것이 좋다.

### 외부 연동이 느려질 때 DB 커넥션 풀 문제

DB 트랜잭션 범위 안에서 외부 연동을 수행할 때, 트랜잭션 처리 외에도 주의해야 할 점이 더 있다.
바로, 외부 연동이 느려지면서 발생하는 커넥션 풀 부족 현상이다. 예를 들어, 기능 실행에 5초가 걸리는 상황을 생각해보자.

1. 커넥션 풀에서 커넥션을 얻는다.
2. 0.1초 걸리는 DB 쿼리를 실행한다.
3. 외부 연동 API를 호출(API 호출에 5초 소요)
4. 0.1초 걸리는 DB 쿼리를 실행한다.
5. 커넥션을 반납한다.

이 시나리오에서 외부 연동을 제외하면, 실제 DB 커넥션이 사용되는 시간은 0.2초에 불과하다.
하지만 외부 연동에 4.8초가 걸리면서 커넥션은 총 5초 동안 사용 상태로 있게 된다.
즉, DB 쿼리를 실행하지 않아도 커넥션이 점유된 상태가 지속되는 것이다.

커넥션 풀의 크기가 5라고 가정해보자. 외부 연동을 포함해 전체 처리 시간은 5초 걸리는 서비스다.

요청이 1초 간격으로 1개씩 들어오면 4초 시점에는 요청 1부터 요청 5까지 총 5개의 요청이 실행 중이 된다.
이때 커넥션 풀에는 남은 커넥션이 0개다.

5초 시점이 되면 요청 1이 종료되면서 커넥션이 반환된다. 이후 요청 6이 해당 커넥션은 풀에서 가져와 바로 사용한다.
요청 6은 대기 시간 없이 커넥션을 확보할 수 있다.

![alt text](/public/images/주니어_백엔드_개발자가_반드시_알아야_할_실무_지식_3.svg)

외부 연동 서비스 시간이 늘어나면 DB 커넥션을 점유하는 시간이 길어지게 된다.
이에 따라 이후 요청 또한 커넥션을 확보하지 못하고 대기하게 된다.

DB 연동과 무관하게 외부 연동을 실행할 수 있다면, DB 커넥션을 사용하기 전이나 후에 외부 연동을 시도하는 방안도 고려해볼 수 있다. 이렇게 하면 외부 연동 시간이 길어지더라도 DB 커넥션 풀이 포화되는 상황을 방지할 수 있다.

단, 이 방식은 외부 연동이 트랜잭션 범위 밖에서 실행되기 때문에 트랜잭션 커밋 이후 외부 연동이 실패하면 롤백이 불가능하다는 점을 고려해야 한다. 이 경우에는 실패한 외부 연동에 대한 후처리를 반드시 고려해야 한다.
트랜잭션으로 반영된 데이터를 되돌리는 보상 트랜잭션을 사용하는 방법 또는 기능 특성에 따라 데이터를 후보정하는 방법 등이 있다.

## HTTP 커넥션 풀

DB 커넥션 풀이 DB 연결에 걸리는 시간을 줄여 성능을 높이는 것처럼 HTTP 연결도 HTTP 연결도 커넥션 풀을 사용하면 연결 시간을 줄일 수 있어 응답 속도 향상에 도움이 된다.

- HTTP 커넥션 풀의 크기
- 풀에서 HTTP 커넥션을 가져올 때까지 대기하는 시간
- HTTP 커넥션을 유지하는 시간(Keep-Alive)

# 5장. 비동기 연동, 언제 어떻게 써야 할까?

## 동기 연동과 비동기 연동

로그인에 성공하면 포인트를 지급하는 기능을 개발해야 할 경우 자연스럽게 다음과 같은 형태의 코드를 떠오른다.

```java
public void login(LoginRequest request) {
    var userOpt = userRepository.findById(request.getUserId());
    if (userOpt.isEmpty()) {
        throw new UserNotFoundException();
    }

    var user = userOpt.get();
    if (!user.matchPassword(request.getPassword())) { // 비밀번호 불일치
        throw new InvalidPasswordException();
    }

    var result = pointClient.addPoint(user.getId(), 1000); // 포인트 지급
    if (result.isFailed()) { // 포인트 지급 실패
        throw new PointAddFailedException();
    }

    // 로그인 내역 추가
    appendLoginHistory(user);
}
```

```mermaid
---
title: 포인트 지급을 실행한 뒤에 로그인 내역을 기록하는 동기 방식
---

sequenceDiagram
  autonumber
  actor user as 사용자
  participant login_service as 로그인 서비스
  participant DB
  participant point_service as 포인트 서비스

  user ->>+ login_service: 로그인 요청

  login_service ->> DB: 회원 정보 조회
  activate DB
  deactivate DB

  login_service ->>+ point_service: 포인트 지급 요청
  point_service -->>- login_service: 포인트 지급 성공

  login_service ->> DB: 내역 기록
  activate DB
  deactivate DB

  login_service ->>- user:
```

포인트 지급에 실패하더라도 로그인 자체는 정상적으로 동작해야 하고 나머지 기능을 사용할 수 있기를 원할 것이다.
이를 위해, 포인트 지급에 실패하면 나중에 후처리할 수 있도록 지급 실패 내역을 따로 남기는 방식으로 코드를 작성할 수 있다.

```java
public void login(LoginRequest request) {
    var userOpt = userRepository.findById(request.getUserId());
    if (userOpt.isEmpty()) {
        throw new UserNotFoundException();
    }

    var user = userOpt.get();
    if (!user.matchPassword(request.getPassword())) { // 비밀번호 불일치
        throw new InvalidPasswordException();
    }

    var result = pointClient.addPoint(user.getId(), 1000); // 포인트 지급
    if (result.isFailed()) { // 포인트 지급 실패하면 후 처리 위해 내역 남김
        recordPointAddFailed(user.getId(), 1000); // 포인트 지급 실패 내역 기록
    }

    // 로그인 내역 추가
    appendLoginHistory(user);
}
```

연동하는 외부 서비스의 응답 시간도 고려해야 한다.
반드시 외부 연동 결과가 필요한게 아니라면, 동기 방식 대신 비동기 방식으로 연동하는 것을 고민해 볼 필요가 있다.
비동기(Asynchronous) 방식은 외부 연동 결과를 기다리지 않고 다음 작업을 진행하는 방식이다.

```mermaid
---
title: 비동기로 외부 연동을 하면 사용자는 빠르게 응답을 받을 수 있다.
---

sequenceDiagram
  autonumber
  actor user as 사용자
  participant login_service as 로그인 서비스
  participant DB
  participant point_service as 포인트 서비스

  user ->>+ login_service: 로그인 요청

  login_service ->> DB: 회원 정보 조회
  activate DB
  deactivate DB

  login_service -->>+ point_service: (비동기) 포인트 지급 요청


  login_service ->> DB: 내역 기록
  activate DB
  deactivate DB

  login_service ->>- user: 로그인 성공 응답

  point_service -->>- login_service: (비동기) 포인트 지급 결과 응답
```

로그인에 성공하고 수 초 뒤에 포인트가 적립되더라도 크게 문제되지 않는다.
사용자 입장에서는 포인트가 쌓이면 되기 때문이다.

생각보다 많은 연동에서 비동기 방식을 사용해도 된다.
다음은 비동기 방식으로 연동해도 크게 문제가 되지 않는 몇 가지 예다.

- 쇼핑몰에서 주문이 들어오면 판매자에게 푸시 보내기 (푸시 서비스 연동)
- 학습을 완료하면 학생에게 포인트 지급 (포인트 서비스 연동)
- 컨텐츠를 등록할 때 검색 서비스에도 등록 (검색 서비스 연동)
- 인증 번호를 요청하면 SMS로 인증 메시지 발송 (문자 서비스 연동)

이 예시들에는 몇 가지 공통적인 특징이 있다.
첫째, 연동에 약간의 시차가 생겨도 문제가 되지 않는다.
예를 들어, 쇼핑몰에서 주문이 완료된 후 1분 뒤에 판매자에게 푸시가 나가도 판매에 지장이 없다.
등록된 컨텐츠가 검색 결과에 10초 뒤에 나타나도 컨텐츠 등록에 문제가 되지 않는다.

둘째, 일부 기능은 실패했을 때 재시도 가능하다. 예를 들어, 푸시 발송에 실패했을 경우 재시도를 통해 푸시가 발송될 수 있다.
학습 완료 후 포인트 지급에 실패했을 때, 몇 초 뒤에 다시 시도하여 포인트 지급에 성공하면 문제가 되지 않는다.
인증 번호 SMS로 오지 않으면 "다시 받기" 기능을 통해 인증 번호를 받을 수 있다.

셋째, 연동에 실패했을 때 나중에 수동으로 처리할 수 있는 기능도 있다. 예를 들어, 검색 서비스 연동에 실패해 컨텐츠가 검색에 노출되지 않는 경우, 컨텐츠 작성자가 검색에 노출되지 않는다고 문의할 때 관리 툴을 사용하여 수동으로 검색 서비스에 등록할 수 있다.

넷째, 연동에 실패했을 때 무시해도 되는 기능도 있다. 예를 들어, 푸시 서비스 연동에 실패했을 때 판매자에게 푸시가 가지 않더라도 큰 문제가 되지 않는다. 단지 주문 확인이 늦어질 뿐이다.
검색이 안되는 경우도 비슷하다. 컨텐츠 등록, 조회, 변경과 같은 기능이 정상적으로 동작하면 일부 컨텐츠가 검색되지 않더라도 서비스를 계속할 수 있다.

- 주문 정보 동기화: 주문 시스템에 생성된 주문 정보를 회원 관리 시스템에 반영할 때 비동기로 동기화했다.
- 택배사에 집하 요창: 회원이 쇼핑몰에서 물건을 주문하면 택배사에 집하 요청을 하는데 비동기로 집하 요청 데이터를 전송했다.

비동기 연동은 다양한 방식으로 구현할 수 있다.

1. 별도 스레드로 실행하기
2. 메시징 시스템 이용하기
3. 트랜잭션 아웃박스 패턴 사용하기
4. 배치로 이동하기
5. CDC 이용하기

## 별도 스레드로 실행하기

예를 들어, 푸시 서비스를 비동기로 연동하고 싶다면 새로운 스레드를 생성하여 연동하는 코드를 실행할 수 있다.

```java
public OrderResult placeOrder(OrderRequest request) {
    // 주문 생성 처리

    // 별도 스레드를 이용해서 푸시를 비동기로 발송
    new Thread(() -> pushClient.sendPush(pushData)).start();

    return successResult(); // 푸시 발송을 기다리지 않고 리턴
}
```

매번 스레드를 생성하는 대신 스레드 풀을 사용하는 방법도 있다.

```java
ExecutorService executorService = Executors.newFixedThreadPool(10);

public OrderResult placeOrder(OrderRequest request) {
    // 주문 생성 처리

    // 스레드 풀을 이용해서 푸시를 비동기로 발송
    executorService.submit(() -> pushClient.sendPush(pushData));

    return successResult(); // 푸시 발송을 기다리지 않고 리턴
}
```

프레임 워크를 제공하는 비동기 기능을 사용하는 방법도 있다.
@Aysnc 애노테이션을 이용한 비동기 실행 기능을 제공한다.

```java
/**
 * 비동기로 실행되는 코드는 연동 과정에서
 * 발생하는 오류를 직접 처리해야 한다.
 */
public class PushService {
    @Async
    public void sendPushAsync(PushData pushData) {
        try {
            pushClient.sendPush(pushData);
        } catch (Exception e) {
            // 오류 처리, 재시도, 로그, 예외 세분화 등등
        }
    }
}
```

비동기로 실행된다는 사실을 다른 작업자들에게 알리기 위해 async 접두사를 붙이도록 한다.
별도 스레드로 실행하면 연동 과정에서 발생한 오류 처리에 더 신경 써야 한다.

> [!NOTE] > **스레드와 메모리**
>
> 스레드는 자체적으로 일정 크기의 메모리를 사용한다.
> 만약 스레드 1개가 사용하는 메모리가 256KiB라고 가정했을 때, 1000개의 스레드를 생성하면 256MiB의 메모리가 필요하다.
> 스레드 풀을 사용하면 스레드를 일정 개수로 유지할 수 있어 메모리 사용량도 일정하게 유지된다.
> 미리 스레드를 생성하므로 스레드를 생성하는 시간도 단축된다.
> 경량스레드(Virtual Thread)를 사용하면 스레드의 메모리 사용량을 줄일 수 있다.

## 메시징

![alt text](/public/images/주니어_백엔드_개발자가_반드시_알아야_할_실무_지식_4.svg)

시스템 A에서 시스템 B를 직접 호출하는 것과 비교하면 메시징 시스템을 사용하면서 구조가 더 복잡해졌지만,
구조가 복잡해지는 대신 다른 이점을 얻을 수 있다.

첫 번째 이점은 두 시스템이 서로 영향을 주지 않는다는 점이다.
시스템 A의 트래픽이 갑자기 증가하면서 전달할 데이터가 시스템 B의 처리량을 초과하는 경우를 생각해보자.
시스템 A에서 시스템 B를 직접 연동했다면 시스템 B에 성능 저하가 발생하고,
그 성능 저하는 다시 시스템 A에까지 영향을 미친다.
그러나 메시징 시스템을 사용하면 시스템 B가 느려지더라도 시스템 A는 영향을 받지 않는다.
즉, 메시징 시스템은 중간에서 메시지를 보관하는 버퍼 역할을 한다.
시스템 A의 트래픽이 급증하더라도 시스템 B는 자신의 용량에 맞게 메시지를 처리할 수 있다.
또한 시스템 B의 성능이 저하되더라도 시스템 A는 영향을 받지 않고 메시지는 메시징 시스템을 통해 전송된다.

메시징 시스템을 사용해 얻을 수 있는 두 번째 이점은 확장이 용이하다는 점이다.
예를 들어, 시스템 A가 시스템 C에도 데이터를 전송해야 한다고 가정하자.
만약 시스템 A가 시스템 C에 직접 데이터를 전송했다면 시스템 A에 새로운 코드를 추가해야 한다.
그러나 메시징 시스템을 사용하면 시스템 C를 메시징 시스템에 연결하기만 하면 된다.
(시스템 B 앞에 Load Balancer를 두고 시스템 B를 확장하는 방법이 흔하기에 이는 조금 공감이 되지 않는다.)

![alt text](/public/images/주니어_백엔드_개발자가_반드시_알아야_할_실무_지식_5.svg)

카프카를 고를 때 고려할 만한 몇 가지 특징은 다음과 같다.

- 높은 처리량을 자랑한다. 초당 백 만 개 이상의 메시지를 처리할 수 있다.
- 수평 확장이 용이하다. 서버(브로커), 파티션, 소비자를 늘리면 된다.
- 카프카는 메시지를 파일에 보관해서 메시지가 유실되지 않는다.
- 1 개의 토픽이 여러 파티션을 가질 수 있는데, 파티션 단위로 순서를 보장한다.
  하지만 토픽 수준에서는 순서를 보장할 수 없다.
- 소비자는 메시지를 언제든지 재처리할 수 있다.
- 풀(Pull) 모델을 사용한다. 소비자가 카프카 브로커에서 메시지를 읽어 가는 방식이다.

래핏MQ의 주요 특징이다.

- 클러스터를 통해 처리량을 높일 수 있다. 단, 카프카보다 더 많은 자원을 필요로 한다.
- 메모리에만 메시지를 보관하는 큐 설정을 사용하면 장애 상황 시 메시지가 유실될 수 있다.
- 메시지는 큐에 등록된 순서대로 소비자에 전송된다.
- 메시지가 소비자에 전달됐는지 확인하는 기능을 제공한다.
- 푸시 모델을 사용한다. 래빗MQ 브로커가 소비자에 메시지를 전송한다.
  소비자의 성능이 느려지면 큐에 과부하가 걸려 전반적으로 성능 저하가 발생할 수 있다.
- 다재 다능하다. AMQP, STOMP 등 여러 프로토콜을 지원하고, 게시/구독 패턴뿐만 아니라 요청/응답, 점대점(point-to-point) 패턴도 지원한다.
  또한, 우선순위를 지정해서 처리 순서를 변경할 수도 있다.

트래픽이 대량으로 발생한다면 카프카를 고려하자.
참고로 여기서 말하는 대량 트래픽은 초당 수 십만에서 수 백만 이상의 메시지를 말한다.
트래픽 규모가 크지 않고 메시지를 정확하게 순서대로 소비자에 전달해야 하거나 AMQP나 STOMP 프로토콜로 연동해야 한다면 래빗MQ를 고려한다.

### 메시지 생성 측 고려 사항

메시지를 생성할 때 고려할 점은 메시지 유실에 대한 것이다.
예를 들어 메시지 전송 과정에서 타임아웃이 발생할 수 있다.
타임아웃 문제는 생산자와 메시징 시스템 간의 네트워크 연결이 불안정하면 언제든지 발생할 수 있다.
이때 오류 처리를 위해 선택할 수 있는 방법에는 다음 3가지가 있다.

- 무시한다.
- 재시도한다.
- 실패 로그를 남긴다.

가장 쉬운 방법은 오류를 무시하는 것이다. 이 경우 메시지는 유실된다.
메시지의 용도에 따라 유실이 일부 허용될 수 있다.
예를 들어, 단순 로그 메시지는 유실되어도 괜찮다.
나중에 로그를 조회할 때 로그가 없으면 아쉬울 수 있지만 기능 동작에 문제는 없다.
또한 로그인 실패 메시지도 유실이 허용될 수 있다.
로그인 실패 메시지를 사용해 로그인 차단 기능을 구현한 소비자 서비스를 생각해보자.
로그인 실패 메시지 전달에 실패하면 로그인 차단 기능은 동작하지 않게 된다.
하지만 나머지 다른 기능은 정상 동작하므로 치명적인 오류는 아니다.

## 트랜잭션 아웃박스 패턴

# 6장. 동시성, 데이터가 꼬이기 전에 잡아야 한다.

## 프로세스 수준에서의 동시 접근 제어

### 잠금(Lock)을 이용한 접근 제어

```java
public class UserSessions {
    private final Lock lock = new ReentrantLock();
    private final Map<String, UserSession> sessions = new HashMap<>();

    public void addUserSession(UserSession session) {
        lock.lock(); // 잠금 획득
        try {
            sessions.put(session.sessionId(), session); // 공유 자원에 접근
        } finally {
            lock.unlock(); // 잠금 해제
        }
    }

    public UserSession getUserSession(String sessionId) {
        lock.lock();
        try {
            return sessions.get(sessionId);
        } finally {
            lock.unlock();
        }
    }
}
```

ReentrantLock을 사용하지 않으면 동시에 여러 스데르가 HashMap의 put() 메서드를 호출하면
데이터가 유실되거나 값이 잘못 저장되는 문제가 발생할 수 있다.

> [!NOTE]
> synchronized와 ReentrantLock
>
> synchronized 키워드를 사용하면 더 간단하게 스레드의 동시 접근을 제어할 수 있다.
>
> ReantrantLock은 synchronized에는 없는 기능을 제공한다. 대표적인 예가 잠금 획득 대기 시간을 지정하는 기능이다.
> 그리고 자바 21 버전에 추가된 가상 스레가 아직 ReantrantLock만 지원하고 synchronized는 자바 24버전부터 지원하고 있다.

```java
class UserSessionsTest {
    @Test
    void concurrentTest() {
        var executorService = Executors.newFixedThreadPool(500);
        var userSessions = new UserSessions();

        var futures = new ArrayList<Future<?>>();

        var sessionCount = 1_000;
        for (int i = 0; i < sessionCount; i++) {
            var sessionId = "sessionId" + i;
            var future = executorService.submit(() -> {
                var userSession = new UserSession(sessionId);
                userSessions.addUserSession(userSession);
            });
            futures.add(future);
        }

        futures.forEach(f -> {
            try {
                f.get();
            } catch (Exception e) {
                e.printStackTrace();
            }
        });

        executorService.shutdown();

        for (int i = 0; i < sessionCount; i++) {
            var sessionId = "sessionId" + i;
            var userSession = userSessions.getUserSession(sessionId);
            assertThat(userSession)
                    .describedAs("session %s", sessionId)
                    .isNotNull();
        }
    }
}
```

> [!NOTE]
> 뮤텍스(Mutex)
>
> 뮤텍스는 mutual exclusion의 약자로, 다른 말로 잠금이라고도 한다.
> 예를 들어 자바 언어는 이름이 Lock인 타입을 사용하고 Go 언어는 Mutex라는 이름을 사용한다.

### 동시 접근을 위한 구성 요소

ReentrantLock은 한 번에 1개 스레드만 잠금을 구할 수 있다. 즉, 한 번에 한 스레드만 공유 자원에 접근할 수 있다. 나머지 스레드는 잠금이 해제될 때까지 대기해야 한다.

잠금 외에도 동시 접근을 제어하기 위한 구성 요소로 세마포어와 읽기 쓰기 잠금이 있다.

### 세마포어(Semaphore)

세마포어는 동시에 접근할 수 있는 스레드의 개수를 제한하는 방식이다.
자원에 대한 접근을 일정 수준으로 제한하고 싶을 때 세마포어를 사용할 수 있다.
외부 서비스에 대한 동시 요청을 최대 5개로 제한하고 싶다면 세마포어를 사용할 수 있다.

세마포어는 허용 가능한 숫자를 이용해서 생성한다. 이 숫자를 자바 세마포어 구현체는 퍼밋(permit)이라고 표현하며,
Go 언어의 세마포어 구현체는 weight라고 표현한다.

> [!NOTE]
> 세마포어에는 이진(binary) 세마포어와 계수(counting) 세마포어가 있다.
> 이진 세마포어는 동시애 접근할 수 있는 스레드가 1개인 반면 계수 세마포어는 동시 접근할 수 있는 스레드의 개수를 지정할 수 있다.

세마포어를 사용하는 전형적인 순서는 다음과 같다.

1. 세마포어세서 퍼밋 획득 (허용 가능 숫자 1 감소)
2. 코드 실행
3. 세마포어에서 퍼밋 해제 (허용 가능 숫자 1 증가)

> [!NOTE]
> 세마포어에서 퍼밋을 구하고 반환하는 연산을 각각 P 연산(또는 wait 연산)과 V 연산(또는 signal 연산)이라고 한다.

```java
public class MyClient {
    private Semaphore semaphore = new Semaphore(5);

    public String getData() {
        try {
            semaphore.acquire(); // 퍼밋 획득 시도
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }

        try {
            // 데이터 처리 로직
            return "data";
        } finally {
            semaphore.release(); // 퍼밋 반환
        }
    }
}
```

허용 개수를 5로 설정했으므로 동시에 5개 스레드가 getData() 메서드를 실행할 수 있다.
나머지 스레드는 퍼밋이 반환될 때까지 대기한다.

### 읽기 쓰기 잠금(Reader-Writer Lock)

```java
public void addUserSession(UserSession session) {
    lock.lock(); // 잠금 획득
    try {
        sessions.put(session.sessionId(), session); // 공유 자원에 접근
    } finally {
        lock.unlock(); // 잠금 해제
    }
}

public UserSession getUserSession(String sessionId) {
    lock.lock();
    try {
        return sessions.get(sessionId);
    } finally {
        lock.unlock();
    }
}
```

addUserSession() 메서드와 getUserSession()은 동일한 잠금을 사용한다.
따라서 session 동시에 put()과 get() 메서드를 호출할 수 없다.

그런데, HashMap이 바뀌지만 않다면 get() 메서드는 동시에 실행할 수 있다.
get() 메서드를 실행하는 동안 put() 메서드가 실행되면 HashMap이 바뀌기 때문에 문제가 된다.
즉, get()과 put() 동시에 실행하지 않고 get()만 동시 실행하는 것은 문제가 되지 않는다.

읽기 쓰기 잠금을 사용하면 이런 성능상 단점을 없애면서 잠금을 통해 데이터 동시 접근 문제를 없앨 수 있다.
읽기 쓰기 잠금은 다음 특징을 갖는다.

- 쓰기 잠금은 한 번에 한 스레드만 구할 수 있다.
- 읽기 잠금은 한 번에 여러 스레드가 구할 수 있다.
- 한 스레드가 쓰기 잠금을 획득했다면 쓰기 잠금이 해제 될 때까지 읽기 잠금을 구할 수 없다.
- 읽기 잠금을 획득한 모든 스레드가 읽기 잠금을 해제할 때까지 쓰기 잠금을 구할 수 없다.

```java
public class UserSessions {
    private final ReadWriteLock lock = new ReentrantReadWriteLock();
    private final Lock writeLock = lock.writeLock();
    private final Lock readLock = lock.readLock();
    private final Map<String, UserSession> sessions = new HashMap<>();

    public void addUserSession(UserSession session) {
        writeLock.lock();
        try {
            sessions.put(session.sessionId(), session); // 공유 자원에 접근
        } finally {
            writeLock.unlock(); // 잠금 해제
        }
    }

    public UserSession getUserSession(String sessionId) {
        readLock.lock();
        try {
            return sessions.get(sessionId);
        } finally {
            readLock.unlock(); // 잠금 해제
        }
    }
}
```

### 원자적 타입 (Atomic Type)

AtomicInteger, AtomicLong, AtomicBoolean는 하드웨어 수준의 Compare-And-Swap(CAS) 명령을 사용하여 잠금 없이(스레드를 멈추지 않고도) 원자적 연산을 수행합니다. 반면 Lock은 운영체제 수준의 동기화 기법을 사용하므로 더 많은 오버헤드가 발생합니다.

동시에 여러 스레드가 int, long, boolean 타입의 공유 데이터를 변경한다면, 잠금 대신 원자적 타입을 사용해서 동시 접근 문제를 간단하게 처리할 수 있다.

### 동시성 지원 컬렉션

동기화된 컬렉션, 즉 데이터를 변경하는 모든 연산에 잠금을 적용해서 한 번에 한 스레드만 접근할 수 있도록 제한하는 것이다.

- ConcurrentHashMap

```java
Map<String, String> map = new HashMap<>();
var map = Collections.synchronizedMap(map);
map.put("key", "value"); // put 메서드는 내부적으로 synchronized로 처리됨
```

> [!NOTE]
> 자바 23 또는 이전 버전 기준으로 가상 스레드를 사용한다면 Collections.synchronizedMap()을 포함한
> 동기화 컬렉션 객체로 변환하는 메서드를 사용하면 안된다.
> 내부적으로 synchronized 키워드를 사용하기 때문에 가상 스레드에서 사용할 수 없다.

> [!TIP]  
> **불변(Immutable) 값**
> 동시성 문제를 피하기 위한 방법 중 하나는 불변(Immutable) 값을 사용하는 것이다.
> 불변 값은 데이터 변경이 필요한 경우, 기존 값을 수정하는 대신 새로운 값을 생성해서 사용한다.
> 예를 들어, 자바의 CopyOnWriteArrayList는 데이터를 변경할 때마다 새로운 배열을 생성해서 사용한다.

## DB와 동시성

DB 트랜잭션만으로는 모든 동시성 문제를 해결할 수 없다.
(DB 마다 차이는 있지만) 대부분의 DB는 명시적인 잠금 기법을 제공한다.
이런 방식은 선점 잠금 또는, 비관적 잠금이라고 한다.
선점 잠금을 사용하면 동일한 레코드에 대해 한 번에 하나의 트랜잭션만 접근할 수 있도록 제어할 수 있다.
반면 값을 비교해서 수정하는 방식은 비선점 잠금, 또는 낙관적 잠금이라고 한다.
쿼리 실행 자체는 막지 않으면서도 데이터가 잘못 변경되는 것을 막을 수 있다.

> [!NOTE]  
> **비관적, 낙관적**
> 왜 비관적이고, 낙관적일까? 여기서 "비관적"은 실패할 가능성이 높아서 비관적이다.
> 다수가 데이터 변경을 시도하면 데이터를 정상적으로 변경할 가능성이 떨어질 테니 이를 비관적이라고 표현한 것이다.
> "낙관적"은 반대로 성공할 가능성이 높아서 낙관적이다.

### 선점(비관적) 잠금(Pessimistic Locking)

선점 잠금은 트랜잭션이 시작될 때 DB에서 레코드를 잠그는 방식이다.

```sql
select * from $테이블 where $조건
for update;
```

이 쿼리는 조건에 해당하는 레코드를 잠금하면서 동시에 잠금을 획득한다. 한 트랜잭션이 특정 레코드에 대한 잠금을 획득한 경우, 잠금을 해제할 때까지 다른 트랜잭션을 동일 레코드에 대한 잠금을 획득하지 못하고 대기해야 한다.
레코드에 대한 잠금은 트랜잭션이 종료될 때(커밋 또는 롤백) 반환된다.

> [!NOTE]  
> **분산 잠금**
> 분산 잠금(distributed lock)은 여러 서버 프로세스가 동시에 동일한 자원에 접근하지 못하도록 막는 방법이다.

### 비선점(낙관적) 잠금(Optimistic Locking)

비선점 잠금은 명시적으로 잠금을 사용하지 않는다.
대신 데이터를 조회하는 시점의 값과 수정하려는 시점의 값이 같은지 비교하는 방식으로 동시성 문제를 처리한다.
보통 비선점 잠금을 구현할 때는 정수 타입의 버전(version) 필드를 사용한다.

1. select 쿼리를 실행할 때 버전 필드도 함께 조회한다.

   ```sql
   select ..., version from $테이블 where $조건;
   ```

2. 로직을 수행한다.
3. Update 쿼리를 실행할 때 version 컬럼을 1 증가시킨다.

   ```sql
   update $테이블 set $컬럼 = ?, version = version + 1 where $조건 and version = ?;
   ```

4. 만약 업데이트 쿼리에서 영향을 받은 레코드 수가 0이라면,
   다른 트랜잭션이 먼저 업데이트를 수행했으므로 롤백한다.

### 외부 연동과 잠금

트랜잭션 범위 내에서 외부 시스템과 연동해야 한다면, 비선점 잠금보다는 선점 잠금을 고려하는 것이 좋다.
예를 들어 주문 취소 과정에서 외부 PG 시스템을 호출해서 결제까지 함께 취소해야 하는 상황을 생각해보자.
이때 비선점 잠금을 사용하면 결제는 이미지 취소됐는데, 데이터 변경에 실패해서 트랜잭션이 롤백되는 문제가 발생할 수 있다.

![alt text](/public/images/주니어_백엔드_개발자가_반드시_알아야_할_실무_지식_6.svg)

비선점 잠금을 사용하고 싶다면 5장에서 살펴본 트랜잭션 아웃박스 패턴을 적용해서 외부 연동을 처리하는 방법도 있다.
저자가 자주 애용하는 방식이기도 하다.

### 증분 쿼리

```java
var subject = jdbcClient.sql("select id, joinCount from subject whrere id = :id")
    .param("id", id)
    .query(Subject.class)
    .single();

// 참여 데이터 추가
joinToSubject(joinData, subject); // subject_join 테이블에 추가

// 참여 수 증가
jdbcClient.sql("update subject set joinCount = :joinCount where id = :id")
    .param("id", id)
    .param("joinCount", subject.getJoinCount() + 1)
    .update();
```

위 코드는 참여자 수를 1 증가시키기 위해 subject 테이블을 업데이트하는 쿼리를 실행한다.
논리적으로는 문제가 없어 보이지만, 하지만 동시에 두 명이 이 코드를 실행하면 joinCount는 2가 아니라 1만 증가하는 문제가 발생할 수 있다.

이 문제를 해결하기 위해 선점 잠금을 사용할 수도 있다.
하지만 선점 잠금을 사용하면 잠금 대기 시간만큼 응답 시간이 길어진다.
비선점 잠금을 사용하면 잠금 대기 시간이 없지만, 변경 실패 에러가 자주 발생할 수 있다.

증분 쿼리를 사용하면 이런 문제를 해결할 수 있다.

```sql
update subject set joinCount = joinCount + 1 where id = :id;
```

> [!NOTE]
> 증분 쿼리는 DB에 따라 원자적 연산이 아닐 수도 있다. 따라서 증분 쿼리를 사용할 때는 사용하는 DB에서 원자적으로
> 처리되는지 반드시 검증해야 한다.

## 잠금 사용 시 주의 사항

### 잠금 해제하기

finally 블록에서 잠금을 해제하는 것을 잊지 말자.

### 대기 시간 지정하기

대기 시간이 길어지는 문제를 막기 위한 방법 중 하나는 대기 시간을 지정하는 것이다.
다음은 잠금 획득 제한을 5초로 설정한 예시이다.

```java
var acquired = lock.tryLock(5, TimeUnit.SECONDS);
if (!acquired) {
    throw new RuntimeException("잠금을 획득하지 못했습니다.");
}

try {
    // 공유 자원에 접근
} finally {
    lock.unlock();
}
```

사용자는 결과를 모른 채 긴 시간 동안 응답을 기다리게 되면 불안감을 느낄 수 있다
(계좌 이체를 하는데 몇 분 동안 응답이 없다면 많이 불안할 것이다).
일정 시간 내에 또는 바로 잠금 획득에 실패하면 사용자에게 빠르게 실패 응답을 줄 수 있다.

### 교착 상태(deadlock) 피하기

한 자원에서 다른 자원으로 용량을 전송하는 기능을 구현한다고 가정해보자.
이 기능을 구현한다면 다음과 같이 두 자원에 대한 잠금이 필요하다.

- 자원 A에 대한 잠금 획득
- 자원 B에 대한 잠금 획득
- 자원 A 용량 감소
- 자원 B 용량 증가
- 자원 B 잠금 해제
- 자원 A 잠금 해제

이렇게 한 작업에서 2개 이상의 자원의 잠금을 획득하는 코드 구조는 교착 상태에 빠지기 쉬운 전형적인 패턴이다.

![alt text](/public/images/주니어_백엔드_개발자가_반드시_알아야_할_실무_지식_7.svg)

교착 상태가 발생하지 않도록 신경 써야 하지만, 복잡한 코드 구조에서 잠금을 사용하면 개발자 자신도
모르게 교착 상태 상황이 발생할 수 있다.
교착 상태를 해소할 수 있는 방법 중 하나는 잠금 대기 시간을 제한하는 것이다.
예를 들어 잠금 대기 시간을 5초로 제한하면 교착 상태가 발생하더라도 5초 뒤에 잠금 대기 시간이 초과되면서 교착 상태가 해소된다.

교착 상태 발생을 줄이는 다른 방법으로는 지정한 순서대로 잠금을 획득하는 방법이 있다.

![alt text](/public/images/주니어_백엔드_개발자가_반드시_알아야_할_실무_지식_8.svg)

- 라이브락(livelock)
- 기아(starvation) 상태

## 단일 스레드로 처리하기

동시성 문제를 피하는 방법이, 바로 한 스레드만 자원에 접근하는 방식을 쓰면 된다.

```mermaid
---
title: 한 스레드만 상태에 접근하기 위한 구조
---

flowchart LR
  thread1[작업 요청 스레드]
  thread2[작업 요청 스레드]
  thread3[작업 요청 스레드]

  queue[작업 큐]

  thread1 --> queue
  thread2 --> queue
  thread3 --> queue

  queue --> stateProcessor[상태 관리 스레드]
```

상태 관리 스레드만 데이터를 조작한다.
데이터 변경이나 접근이 필요한 스레드는 작업 큐에 필요한 작업을 추가할 뿐 직접 상태에 접근하지 못한다.
상태 관리 스레드는 다음 코드처럼 작업 큐에 있는 작업을 처리한다.

```java
while (running) {
    var job = queue.poll(1, TimeUnit.SECONDS);
    if (job == null) {
        continue;
    }

    switch (job.getType()) {
        case INC:
            obj.modifyState();
            break;
        // ... 다른 작업
    }
}
```

이 코드에서 obj.modifyState() 메서드는 한 스레드만 접근하기 때문에 잠금과 같은 수단이 필요 없어 코드가 단순해진다.

Go 언어에서는 "메모리를 공유하는 방식으로 (고루틴 간에) 소통하지 말고, 통신을 통해 메모리를 공유하라"는 말이 있다.
Go 언어는 여러 고루틴이 동시에 접근하는 것을 제어하기 위한 잠금 수단을 제공하고 있지만,
그보다는 채널을 통해 고루틴 간에 데이터를 공유하는 방식으로 동시성을 구현하는 것을 권장한다.

```mermaid
---
title: Go 언어는 채널을 통해 데이터를 공유하는 방식으로 동시성을 구현할 수 있다.
---
flowchart LR
  goRoutine1[고루틴] --> channel[채널] --> goRoutine2[고루틴]
```

논블로킹이나 비동기 I/O를 사용하는 경우에는 블로킹 연산을 최소화해야 하므로 단일 스레드 처리 방식이 적합하다.

# 7장. I/O 병목, 어떻게 해결하지

```mermaid
---
title: 서버는 다양한 구성 요소와 네트워크로 데이터를 주고받는다.
---

flowchart LR
  client[클라이언트] --> server[서버]
  server --> Db
  server --> redis
  server --> externalAPI[외부 API]
```

네트워크를 통해 데이터를 주고받는 과정은 간단하게 다음 두 줄로 정리할 수 있다.

```java
outputStream.write(data); // 출력 스트림으로 데이터 보내기
inputStream.read(data); // 입력 스트림으로 데이터 받기
```

![alt text](/public/images/주니어_백엔드_개발자가_반드시_알아야_할_실무_지식_9.svg)

데이터 입출력이 완료될 때까지 스레드는 아무 작업도 하지 않고 입출력이 끝나기를 기다린다.
즉 입출력이 끝날 때까지 스레드가 블로킹(blocking)된다.
보통 입출력에 소요되는 시간은 코드를 실행하는 시간보다 훨씬 길다.
서버처럼 네트워크 연동이 많은 프로그램은 전체 실행 시간의 90% 이상을 입출력 대기에 사용하는 경우도 있다.

> [!NOTE]
> 전체 실행 시간의 90% 이상을 입출력 대기에 사용되고, CPU 사용 시간이 고작 5ms 였던 경우도 있따.

스레드가 대기하는 데 시간을 소요한다는 것은, 그 스레드를 실행하는 CPU도 아무것도 하지 않느 시간이 생긴다는 의미이다. CPU 사용률을 높이려면 CPU가 실행할 스레드를 많이 만들면 된다.
요청당 스레드 방식으로 구현한 서버가 이에 해당한다.
동시에 실행되는 스레드 개수를 늘려 IO 대기에 따른 CPU 낭비를 줄일 수 있다.

하지만 스레드를 생성하는 데는 한계가 있다. 스레드는 수백 KB에서 수 MB의 메모리를 사용한다.
커넥션당 스레드 방식으로 구현한 웹소켓 서버는 1만 명의 사용자가 동시에 연결했다고 하면,
스레드 1만 개를 생성하는 것만으로 사용하는 메모리는 10GB에 달한다.

메모리를 늘려 스레드를 많이 만들 수 있게 되더라도 여전히 문제는 남는다. 바로 컨텍스트 스위칭이다.
동시에 실행되는 스레드가 증가하면 컨텍스트 스위칭에 사용되는 시간도 증가한다.
컨텍스트 스위칭에 들어가는 시간은 짧지만, 동시 실행되는 스레드가 많아지면 CPU 효율에 영향을 준다.

> [!NOTE]
> 정리하면 트래픽이 증가하면 다음 2가지 이유로 자원 효율이 떨어지게 된다.
>
> - IO 대기와 컨텍스트 스위칭에 따른 CPU 낭비
> - 요청마다 스레드를 할당함으로써 메모리 사용량이 높음

여기까지 보면 왜 톰캣처럼 요청마다 스레드를 할당하는 서버를 사용하는지 궁금하다.
서버는 DB나 API 호출 같은 입출력 처리가 많고, 이는 톰캣 같은 서버를 사용하면 CPU와 메모리 낭비가 많다는 것을 뜻하기 때문이다.

그런데 다수의 서비스는 서버의 자원 낭비를 걱정할 필요가 없다. CPU와 메모리 사용에 영향을 줄 만큼 트래픽이 발생하지 않기 때문이다.

수백만 또는 수천만 이상의 고객이 사용할 정도리 인기 있는 서비스가 아니라면 CPU와 메모리 자원 부족보다는
다른 이유로 서버 성능이 저하되는 경우가 많다.

서비스가 인기를 끌기 시작하면 트래픽이 증가하고 이때부터 처리량을 더 높이기 위한 방법을 고민하면 된다.
수평 확장 방법을 먼저 적용하자.

서버 성능을 높이는 또 다른 방법은 자원 효율을 높이는 것이다.
IO 대기로 인한 CPU 낭비를 줄이고 요청을 처리하는 데 필요한 메모리를 줄이는 것이다.

- 가상 스레드나 고루틴 같은 경량 스레드 사용
- 논블로킹 또는 비동기 I/O 사용

> [!NOTE]  
> 성능을 높이겠다고 처음부터 비동기 IO로 개발하거나 가상 스레드를 적용하지는 말자.
> 실제로 IO 성능을 높여야 할 만큼 트래픽이 증가하고 있거나 예상되는 트래픽이 높은 경우에만 적용 여부를 고민하자.

## 가상 스레드로 자원 효율 높이기

코드를 블로킹 IO로 작성했는데, 입출력 동안 스레드가 대기하지 않고 다른 일을 할 수 있다면 얼마나 좋을까?
바로 자바의 가상 스레드나 Go 언어의 고루틴이 이런 방식으로 동작한다.

경량 스레드는 OS가 관리하는 스레드가 아니라 JVM(자바 가상 머신) 같은 언어의 런타임이 관리하는 스레드다.
마치 OS가 CPU로 실행할 스레드를 스케줄링하듯, 언어 런타임이 OS 스레드로 실행할 경량 스레드를 스케줄링한다.

![alt text](/public/images/주니어_백엔드_개발자가_반드시_알아야_할_실무_지식_10.svg)

JVM은 기본적으로 풀에 CPU 코어 개수만큼 플랫폼 스레드를 생성하고 필요에 따라 플랫폼 스레드를 증가시킨다.

가상 스레드를 경량 스레드라고 부르는 이유는 플랫폼 스레드보다 더 작은 자원을 사용하기 때문이다.
우선 가상 스레드는 플랫폼 스레드(OS 스레드)보다 메모리 사용량이 적다.

> [!NOTE]  
> 가상 스레드와 메모리
> 가상 스레드는 수백 바이트에서 수 KB ~ 수십 KB 정도의 힙 메모리를 사용한다.
> 호출 스택의 깊이에 따라 메모리를 동적으로 늘렸다가 줄인다.
> Go 언어의 고루틴도 동일한 방식으로 동작한다.

이는 톰캣처럼 요청별 스레드를 생성하는 서버에서 가상 스레드를 사용하면 더 적은 메모리로 더 많은 요청을 처리할 수 있다는 것을 뜻한다.

> [!NOTE]  
> 캐리어(carrier) 스레드  
> 가상 스레드를 실행하는 플랫폼 스레드를 캐리어 스레드라고 표현한다. CPU가 여러 스레드를 실행하는 것처럼,
> 한 개의 캐리어 스레드도 여러 개의 가상 스레드를 실행하게 된다.
> 특정 가상 스레드가 특정 캐리어 스레드에 연결되는 것을 마운트(mount)되었다고 표현한다.
> 반대로 가상 스레드가 캐리어 스레드로부터 언마운트(unmount)되면 가상 스레드는 실행을 멈춘다.

### 네트워크 IO와 가상 스레드

가상 스레드는 실행하는 과정에서 블로킹되면 플랫폼 스레드와 언마운트되고 실행이 멈춘다.
이때 언마운트된 플랫폼(캐리어) 스레드는 실행 대기 중인 다른 가상 스레드와 연결된 뒤 실행을 재개한다.

> [!NOTE]  
> 블로킹 연산관 synchronized  
> 블로킹 연산에는 IO기능, ReentrantLock, Thread.sleep() 등이 있다.
> 이들 연산을 사용해서 가상 스레드가 블로킹되면, 플랫폼 스레드는 대기 중인 다른 가상 스레드를 실행한다.
> 반면에 자바 23 또는 이전 버전에서 synchronized로 인해 블로킹되면,
> 가상 스레드는 플랫폼 스레드로부터 언마운트되지 않는다.
> 즉, 플랫폼 스레드도 같이 블로킹된다.
> 이렇게 가상 스레드가 플랫폼 스레드까지 블로킹할 때 이를 가상 스레드가 플랫폼 스레드에 고정됐다(pinned)고 표현한다.
>
> 자바 21 기준으로 synchronized 외에도 JNI 호출 등 가상 스레드가 플랫폼 스레드에 고정되는 경우가 있는데,
> 가상 스레드가 고정되면 CPU 효율을 높일 수 없다.

### 가상 스레드와 성능

코드는 크게 IO 중심(IO-bound)과 CPU 중심(CPU-bound)으로 나눌 수 있다.
네트워크 프로그래밍처럼 입출력이 주를 이루는 작업은 IO 중심이라고 한다.
반대로 정렬처럼 계산이 주를 이루는 작업은 CPU 중심이라고 한다.

이 두 작업 중 가상 스레드는 IO 중심 작업일 때 효과가 있다.
IO는 가상 스레드가 지원하는 블로킹 연산이므로, IO 중심 작업일 때 플랫폼 스레드가 CPU 낭비 없이 효율적으로 여러 가상 스레드를 실행할 수 있다.

CPU 중심 작업에 가상 스레드를 사용하면 성능 개선 효과를 얻을 수 없다. 오히려 성능이 저하될 수 있다.
사용자가 업로드한 이미지의 썸네일을 생성해주는 작업을 예로 들어보자.
이미지 연산은 전형적인 CPU 중심 작업이다.
이미지를 처리하는 코드에는 블로킹 연산이 없다.
블로킹 연산이 없으므로 이미지 연산을 실행하는 동안 플랫폼 스레드는 계속 1개의 가상 스레드만 실행하게 된다.
가상 스레드를 많이 생성하더라도 동시 실행 효과를 얻을 수 없다.
CPU 중심 작업은 플랫폼 스레드(코어 수)만큼만 스레드를 만들어서 돌리는 것이 가장 효율적이다.

또한 IO 중심 작업이라고 해서 무조건 가상 스레드의 이점을 얻는 것은 아니다.
스케줄링에 사용되는 플랫폼 스레드 개수보다 가상 스레드의 개수가 많아야 효과를 기대할 수 있다.
예를 들어 다음과 같은 상황을 가정해보자.

- 장비 CPU 코어는 16개
- 서버의 평소 TPS는 500
- 1개 요청을 처리하는데 소요되는 시간은 20ms
- 모든 요청은 IO 중심 작업

단순 계산하면 1개의 스레드는 1초 동안 약 50개의 요청을 처리할 수 있다. (20ms \* 50 = 1000ms)
1초에 500개 요청을 처리하려면 스레드 개수는 10개가 필요하다.

이 서버에 가상 스레드를 사용하면 다음과 같이 오히려 플랫폼 스레드가 더 많이 생기는 상황이 벌어진다.

- 플랫폼 스레드는 기본으로 16개가 생성된다. (CPU 코어 수)
- 동시 요청은 10개이므로 동시에 생성되는 가상 스레드는 10개다.

동시에 10개의 가상 스레드가 실행되지만 IO중심 작업이기 때문에 대부분 시간이 IO 대기 상태에 있다.
플랫폼 스레드는 실행 중인 가상 스레드가 IO 대기로 블로킹되면 실행할 수 있는 다른 가상 스레드를 찾는다.
그런데 대부분의 가상 스레드가 IO 대기 중이라 실행할 수 있는 가상 스레드가 많지 않다.
결과적으로 플랫폼 스레드 16개 중 실제로 사용되는 스레드는 10개도 안된다.
가상 스레드는 플랫폼 스레드보다 개수가 많을 때 효과가 있기 떄문이다.

가상 스레드를 사용해서 높일 수 있는 것은 처리량이다.

> [!NOTE]  
> 가상 스레드와 스레드 풀  
> 가상 스레드는 플랫폼 스레드보다 생성 비용이 적기 때문에 스레드 풀을 미리 구성할 필요가 없다.
> 필요한 시점에 가상 스레드를 생성하고 필요 없으면 제거하면 된다.

### Spring에서 Async 비교

```java
@SpringBootTest(classes = AsyncServiceTest.TestConfig.class)
@EnableAsync
@TestPropertySource(properties = {
        "spring.threads.virtual.enabled=true",
        "spring.task.execution.pool.core-size=5",
        "spring.task.execution.pool.max-size=10",
})
class AsyncServiceTest {

    @Autowired
    private AsyncService asyncService;

    @Test
    void compareVirtualVsFixedThreadPool() {
        int taskCount = 1000;

        long startVirtual = System.currentTimeMillis();
        CompletableFuture<?>[] virtualFutures = new CompletableFuture[taskCount];
        for (int i = 0; i < taskCount; i++) {
            virtualFutures[i] = asyncService.asyncWithVirtualExecutor();
        }
        CompletableFuture.allOf(virtualFutures).join();
        long endVirtual = System.currentTimeMillis();
        System.out.println("VirtualThread 전체 소요 시간: " + (endVirtual - startVirtual) + "ms");

        long startFixed = System.currentTimeMillis();
        CompletableFuture<?>[] fixedFutures = new CompletableFuture[taskCount];
        for (int i = 0; i < taskCount; i++) {
            fixedFutures[i] = asyncService.asyncWithFixedExecutor();
        }
        CompletableFuture.allOf(fixedFutures).join();
        long endFixed = System.currentTimeMillis();
        System.out.println("FixedThreadPool 전체 소요 시간: " + (endFixed - startFixed) + "ms");
    }

    static class AsyncService {
        @Async("ioInboundExecutor")
        public CompletableFuture<String> asyncWithVirtualExecutor() {
            String threadName = Thread.currentThread().toString();
            System.out.println("실행 스레드(Virtual): " + threadName);
            try {
                Thread.sleep(2_000); // 2초 대기 (비동기 작업 시뮬레이션)
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
            return CompletableFuture.completedFuture("done");
        }

        @Async("cpuInboundExecutor")
        public CompletableFuture<String> asyncWithFixedExecutor() {
            String threadName = Thread.currentThread().toString();
            System.out.println("실행 스레드(Fixed): " + threadName);
            try {
                Thread.sleep(2_000); // 2초 대기 (비동기 작업 시뮬레이션)
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
            return CompletableFuture.completedFuture("done");
        }
    }

    @SpringBootConfiguration
    static class TestConfig {
        @Bean
        public Executor ioInboundExecutor() {
            return Executors.newVirtualThreadPerTaskExecutor();
        }

        @Bean
        public Executor cpuInboundExecutor() {
            var threadPoolTaskExecutor = new ThreadPoolTaskExecutor();
            threadPoolTaskExecutor.setCorePoolSize(5);
            threadPoolTaskExecutor.setMaxPoolSize(10);
            threadPoolTaskExecutor.setThreadNamePrefix("CPU-Bound-Executor-");
            return threadPoolTaskExecutor;
        }

        @Bean
        public AsyncService asyncService() {
            return new AsyncService();
        }
    }
}
```

## 논블로킹 IO로 성능 더 높이기

사용자가 폭발적으로 증가하면 어는 순간 경량 스레드로도 한계가 온다.
이때는 서버의 IO 구현 방식을 구조적으로 변경해야 한다. 바로 논블로킹 IO를 사용해야 하는 것이다.
Nginx, Netty, Node.js 등 서버에서 많이 사용하는 기술은 성능을 높이기 위해 논블로킹 IO를 사용한다.

### 논블로킹 IO 동작 개요

논블로킹 IO는 입출력이 끝날 때까지 스레드가 대기하지 않는다.
논블로킹 IO를 이용해서 구현한 서버는 블로킹 IO를 이용한 구현과 차이가 난다.
일반적으로 블로킹 IO로 구현한 서버는 커넥션별로 스레드를 할당한다.
동시 연결 클라이언트가 1,000개면 스레드도 1,000개가 생성된다.
반면에 논블로킹 IO로 구현한 서버는 클라이언트 수에 상관없이 소수의 스레드를 사용한다.

### 리액터 패턴

리액터 패턴은 논블로킹 IO를 구현할 때 사용하는 패턴 중 하나다.
논블로킹 IO로 구현된 네트워크 프레임워크 문서를 읽다 보면 '리액터'라는 단어를 자주 보게 된다.

리액터 패턴은 동시에 들어오는 여러 이벤트를 처리하기 위한 이벤트 처리 방법이다.
리액터 패턴은 크게 리액터와 핸들러로 나눌 수 있다.
리액터는 이벤트를 감지하고 핸들러는 이벤트가 발생했을 때 처리하는 역할을 한다.

```java
while (running) {
    var events = selector.select(); // 이벤트가 발생할 때까지 대기
    for (var event : events) {
        var handler = handlers.get(event);
        handler.handle(event); // 이벤트 처리
    }
}
```

이 코드를 보면 리액터는 이벤트를 대기하고 핸들러에 전달하는 과정을 반복하는데,
그래서 리액터를 이벤트 루프라고도 한다.

리액터 패턴에서 이벤트 루프는 단일 스레도 실행된다.
멀티 코어를 가진 서버에서 단일 스레드만 사용하면 처리량을 최대한 낼 수 없다.
또 핸들러에서 CPU 연산이나 블로킹을 유발하는 연산을 수행하면 그 시간만큼 전체 이벤트 처리 시간이 지연된다.
이런 한계를 보완하기 위해 핸들러나 블로킹 연산을 별도 스레드 풀에서 실행하기도 한다.
예를 들어 Netty는 여러 이벤트 루프를 생성해서 멀티 코어를 활용한다.
Node.js는 이벤트 루프 외에 별도의 스레드 풀을 사용해서 CPU 중심 작업이나 블로킹 연산을 동시에 처리한다.

### 논블로킹/비동기 IO와 성능

논블로킹 IO(120,000)가 블로킹 IO(6,000)에 비해 최대 동접수 20배 정도 성능이 향상된다고 한다. (JVM: Heap Memory 1.5G)

- gent(180,000) 고루틴(20,000)

## 언제 어떤 방법을 택할까

가장 먼저 검토해야 할 점은 성능 문제가 있는지 여부다.
성능 문제가 없다면 또는 당분간 트래픽 증가 가능성이 없다면 논블로킹 IO나 가상 스레드를 검토할 필요가 없다.

성능 문제가 있다면 그 문제가 네트워크 IO에 관련된 자원 문제인지 확인해야 한다.
예를 들어 트래픽은 그대로인데 DB 쿼리 시간이 느려지면서 서버 응답 시간이 길어지는 문제가 발생했다면
가상 스레드나 논블로킹 IO를 사용해도 성능 개선 효과를 얻을 수 없다.
이 경우에는 DB 쿼리를 최적화하거나 캐시를 사용하는 것이 응답 시간을 줄이는 방법이다.
CPU 중심 작업도 마찬가지다.

문제가 IO 관련이라면 그때는 구현 변경이 가능한지를 확인해야 한다.
예를 들어 동시에 요청하는 클라이언트 수가 늘어나면서 실행되는 스레드 수가 많아졌고,
그 결과 메모리 사용률이 98%까지 올라갔다고 하자.
가상 스레드 적용할 수 있다면 이를 통해 메모리 사용률을 줄일 수 있다.
만약 가상 스레드를 적용할 수 없다면 메모리를 일단 늘리거나 서버를 수평 확장해서 문제를 완화하는 수밖에 없다.

# 8장. 실무에서 꼭 필요한 보안 지식

## 인증과 인가

아이디와 암호를 입력하는 로그인은 인증의 한 형태다.
보안을 강화하기 위해 2FA(2 Factor Authentication)나 OTP(One Time Password)를 사용하는 경우도 있다.

```mermaid
---
title: 서버는 인증에 성공하면 고유한 토큰을 응답에 전송한다.
---

sequenceDiagram
    autonumber
    participant Client as 클라이언트
    participant Server as 서버

    Client->>+Server: 인증 요청
    Server->>Server: 아이디, 암호 확인
    Server->>Server: 토큰 생성
    Server-->>-Client: 인증 성공, 토큰 전송
    Client->>+Server: 요청 (토큰 포함)
    Server->>Server: 토큰 검증 및 사용자 식별
    Server->>Server: 요청 처리
    Server-->>-Client: 응답
```

토큰을 이용해서 사용자를 식별하려면 토큰과 사용자 간의 매핑 정보를 어딘가에 저장해야 한다.
이 매핑 정보를 저장할 위치로는 크게 두 가지가 있다.

- 서버의 별도 저장소: 별도 저장소에 토큰과 사용자 식별 정보를 저장한다.
- 토큰: 토큰 자체에 사용자 식별 정보를 저장한다.

**✅ 별도 저장소에 토큰과 사용자 식별자 정보 저장하기**

서버는 토큰과 사용자 식별 정보를 DB나 레디스와 같은 별도 저장소에 보관할 수 있다.
토큰 문자열을 생성할 때는 고유한 값을 생성해서 토큰 중복으로 인해 사용자 정보가 잘못 매칭되지 않도록 해야 한다.

![alt text](/public/images/주니어_백엔드_개발자가_반드시_알아야_할_실무_지식_11.svg)

외부 저장소에 사용되는 정보는 다음과 같다.

- 토큰
- 사용자 식별자
- 생성 시간
- 최근 사용 시간
- 그 외 유효 시간, 클라이언트 버전 등 추가 데이터

서버는 클라이언트가 전송한 토큰을 이용해서 저장소에서 사용자 식별자를 구한다.

```java
var token = ...; // 클라이언트가 전송한 토큰
var toeknOpt = tokenStore.getToken(token);
var tokenData = tokenOpt.orElseThrow(() -> new TokenNotFoundException(token));
```

토큰 데이터는 크기가 크지 않기 때문에 수백만 개의 토큰을 저장해도 DB 용량에 큰 부담은 없다.
예를 들어 340만 개의 토큰 데이터를 저장하고 있는데, 토큰 테이블의 크기가 대략 2.4G 정도다.
레디스가 같은 메모리 캐시를 사용해도 충분히 저장할 수 있는 크기다.

**✅ 토큰 자체에 사용자 식별자 정보 저장하기**

토큰 자체에 사용자 식별 정보를 저장할 수도 있다. 대표적인 방식이 JWT(JSON Web Token)다.
사용자가 로그인에 성공하면 사용자 식별자를 값으로 갖는 JWT를 생성해서 클라이언트 토큰으로 응답한다.

```java
var token = Jwts.builder()
            .subject(userId) // 사용자 식별자
            .signWith(key)
            .compact();
return Response.success(token);
```

서버는 클라이언트가 전송한 토큰으로부터 사용자 식별자를 구한다.

```java
try {
    Jws<Claims> jwt = Jwts.parser()
            .verifyWith(key)
            .build()
            .parseClaimsJws(jws);

    var userId = jwt.getBody().getSubject(); // 사용자 식별자
} catch (JwtException e) {
    throw new AuthenticationException(e);
}
```

**✅ 토큰 보안**

토큰 유효 시간을 제한을 둔다.
토큰 유효 시간에는 2가지 방식이 존재한다.
첫 번째는 토큰 생성 시점을 기준으로 제한 시간을 두는 방식이다.
두 번째는 마지막 접근 시간을 기준으로 토큰 유효 시간을 정하는 것이다.
토큰 유효 시간은 어플리케이션 성격에 따라 알맞게 정한다.
관리자 사이트처럼 민감 정보를 조회할 수 있는 서비스는 유효 시간을 길게 잡으면 안 된다.

유효시간과 함께 클라이언트 IP를 비교하면 토큰 보안이 향상된다.
토큰을 생성할 때 접근한 클라이언트 IP와 실제 토큰을 전송한 클라이언트 IP가 같은지 비교한다.
IP가 다르면 비정상 접근으로 간주하고 요청 처리를 거부한다.

보안 사고 영향을 줄이고 싶다면 토큰을 무효화해서 강제로 로그아웃시키는 기능도 필요하다.
토큰 데이터를 DB나 레디스와 같은 외부 저장소에 보관하면 토큰 데이터를 삭제하거나 유효하지 않은
상태로 변경해서 토큰을 무효화할 수 있다.

> [!NOTE]  
> 토큰 재발급  
> 액세스 토큰의 만료 시간이 짧으면 사용자의 로그인이 풀려 불편을 줄 수 있다.
> 이때 다시 액세스 토큰을 발급받아 로그인을 다시 하지 않아도 인증 상태를 유지할 수 있게 해주는 토큰이 리프레시 토큰이다.
>
> 액세스 토큰과 리프레시 토큰을 지원하는 시스템은 사용자가 로그인에 성공하면 만료 시간이 짧은 액세스 토큰과 함께 만료 시간이 상대적으로 긴 리프레시 토큰을 함께 발급한다.
> 이후 액세스 토큰이 만료되면 리프레시 토큰을 이용해서 새로운 액세스 토큰을 발급해 준다.

### 인가와 접근 제어 모델

인가는 사용자가 요청한 기능르 실행할 권한이 있는지 확인하는 역할을 한다.

서비스에 따라 사용자마다 실행할 수 있는 기능에 차이를 두기도 한다.
많은 고객 관리자 사이트는 운영자에 따라 접근 가능한 메뉴에 차이가 있고,
중고 거래 사이트는 유료 고객에게만 특별 노출 기능을 제공하기도 한다.

사용자가 접근할 수 있는 기능(또는 자원)을 관리하기 위한 모델을 접근 제어(Access Control) 모델이라고 한다.
대표적인 접근 제어 모델로는 역할 기반 접근 제어(RBAC)와 속성 기반 접근 제어(ABAC)가 있다.

![alt text](/public/images/주니어_백엔드_개발자가_반드시_알아야_할_실무_지식_12.svg)

역할은 허용된 기능 집합을 가진다.
사용자에게는 역할을 부여한다.

사용자는 역할을 여러 개 가질 수 있고, 역할은 여러 사용자를 가질 수 있다.
역할은 허용 기능을 여러개 가질 수 있고, 허용 기능 또한 여러 개의 역할을 가질 수 있다.

역할을 두지 않고 사용자마다 개별적으로 권한을 부여할 수도 있다.

사용자의 속성을 이용해서 접근을 제어하는 속성 기반 접근 제어(Attribted-Based Access Control) 모델도 있다.
예를 들어, 사용자의 IP 주소에 따라 특정 기능의 접근을 허용하거나 제한할 수 있다.

### Salt로 보안 강화하기

같은 해시 알고리즘을 사용하면 동일한 원본 데이터에 대해 항상 동일한 해시 값이 생성된다.
이 특성은 해시 값이 유출됐을 때 원본을 유추하기 쉽게 만든다.

해커가 탈취한 해시 값이 "hash123"이라면, 레인보우 테이블을 참고해서 "pwd1"의 해시 값이라는 것을 알 수 있고,
이렇게 같은 원본 데이터에 대해 동일한 해시 값을 생성하는 것은 보안에 취약하다.
사용자마다 고유한 값을 생성해서 솔트로 사용하면 된다.

### 양방향 암호화

대칭 키 암호화는 암호화와 복호화를 동일한 키로 수행한다.
비대칭 키 암호화는 암호활 할 때와 복호화 할 때 서로 다른 키를 사용한다.
비대칭 키 암호화에서는 공개 키와 개인 키를 생성한다.
공개 키는 누구에게나 공개할 수 있는 키이다. 반대로 개인 키는 소유자만 접근할 수 있어야 한다.
공개 키는 데이터를 암호화할 때 사용하고, 개인 키는 암호화된 데이터를 복호화할 때 사용한다.

키 소유자는 공개 키와 개인 키 쌍을 생성한 뒤, 데이터 송신자에게 공개 키를 제공한다.

개인 키로 암호화하고 공개 키로 복호화할 수도 있다.
보통 개인 키로 데이터를 암호화하는 것은 신원 확인이나 서명과 같은 인증 목적으로 사용된다.
개인 키를 사용해서 인증을 수행하는 예로는 SSH를 들 수 있다.
SSH 서버에 공개 키를 등록하고, 클라이언트는 서버에 접속하 때 개인 키를 사용해서 인증을 수행한다.

> [!NOTE]
> SSH의 키 쌍을 이용한 사용자 인증 과정
>
> 1. 클라이언트는 인증에 사용할 키 쌍의 ID를 서버에 전송한다.
> 2. 서버는 키 ID에 해당하는 공개 키를 authorized_keys 파일에서 찾는다.
> 3. 공개 키가 존재하면 임의의 숫자를 생성해서 공개 키로 암호화한다.
> 4. 암호화한 숫자를 클라이언트에 전송한다.
> 5. 클라이언트는 개인 키로 암호화된 숫자를 복호화한다.
> 6. 클라이언트는 복호화된 숫자와 공유 세션 키를 결합한 값의 해시를 구한다.
> 7. 해시 값을 서버에 전송한다.
> 8. 서버는 클라이언트가 보낸 해시 값과 서버에서 구한 해시 값을 비교한다.
> 9. 두 값이 일치하면 인증이 성공한다.

# 9장. 최소한 알고 있어야 할 서버 지식

## 파일 디스크립터 제한

프로세스는 데이터 입출력이 필요할 때 OS로부터 파일 디스크립터를 할당받는다.
예를 들어 파일 입출력이나 소켓을 이용한 네트워크 입출력을 처리할 때 파일 디스크립터를 할당받아 사용한다.

OS는 사용자나 시스템 수준에서 생성할 수 있는 파일 디스크립터 개수를 제한한다.
프로세스는 제한된 개수의 파일 디스크립터를 초과해서 생성할 수 없다. 예를 들어 사용자의 파일 디스크립터 개수 제한이 1024라면 프로세스는 파일과 소켓을 합쳐 1024개를 초과해서 열 수 없다.
파일 디스크립터 개수 제한을 초과하면 Too many open files 에러가 발생한다.

> [!NOTE]  
> .bash_profile 파일과 .bashrc 파일
>
> .bash_profile 파일과 .bashrc 파일은 둘 다 bash 셸에서 사용자 환경을 구성할 때 사용되는 설정 파일이다.
> 이 두 파일은 실행되는 시점과 용도가 다르다.
>
> 1. .bash_profile 파일은 사용자가 로그인할 때 한 번 실행된다. 보통 이 파일에는 PATH 처럼 전체 세션에 필요한 환경 변수를 설정한다.
> 2. .bashrc 파일은 사용자가 새로운 셸을 열 때마다 실행된다. 보통 이 파일에는 alias와 같은 셸 관련 설정을 한다.
> 3. .bash_profile 파일에서 .bashrc 파일을 호출하면 로그인할 때마다 .bashrc 파일도 실행된다.
>
>    ```sh
>     # .bash_profile
>     if [ -f ~/.bashrc ]; then
>        . ~/.bashrc
>     fi
>    ```

## 네트워크 정보 확인

### nc 명령어로 연결 확인하기

다음은 nc를 이용해서 443 포트로 연결이 되는지 확인하는 명령어의 예이다.

```sh
$ nc -zv google.com 443
Connection to google.com port 443 [tcp/https] succeeded!
```

- -z: 데이터 전송 없이 특정 포트가 열려 있는지 확인한다.
- -v: 연결 상태를 자세히 출력한다.
- -u: UDP 포트가 열려있는지 확인할 때는 -u 옵션을 추가한다.

nc를 사용하면 특정 포트를 사용하는 서버를 구동할 수도 있다.
이를 사용하면 실제 서버 프로세스를 구동하기 전에 두 노드 간에 통신이 제대로 동작하는지 확인할 수 있다.

```sh
$ nc -lvp 8080
```

- -l: 리스닝 모드로 실행한다.
- -p: 클라이언트 요청을 수신할 포트를 지정한다.

### netstat 명령어로 포트 확인하기

서버 프로세스가 구동되어 있는데 해당 포트로 연결이 안 된다면, 실제 포트로 클라이언트 연결을 기다리고 있는지
확인해야 하는데 이때 사용할 수 있는 명령어가 netstat이다. netstat는 명령어를 사용하면 현재 사용 중인 소켓의 IP와 포트를 확인할 수 있다.

다음 netstat 명령어를 사용하면 현재 서버에서 열려 있는 서버 포트를 확인할 수 있다.

```sh
$ netstat -lputn
```

- -l: 리스닝 중인 포트만 출력한다.
- -p: 프로세스 ID와 프로세스 이름을 출력한다.
- -u: UDP 포트도 출력한다.
- -t: TCP 포트도 출력한다.
- -n: IP 주소와 포트를 숫자로 출력한다. (도메인 이름을 해석하지 않는다.)

현재 사용 중인 전체 포트를 확인하고 싶다면 -a 옵션을 추가하면 된다.
다음처럼 netstat -anp 명령어와 grep을 함께 사용하면 특정 포트만 확인할 수 있다.

```sh
$ netstat -anp | grep 8080
```
